{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/steven/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/steven/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in /home/steven/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: wheel in /home/steven/anaconda3/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/steven/anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/steven/anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:25:59.618292Z",
     "iopub.status.busy": "2022-01-23T02:25:59.616635Z",
     "iopub.status.idle": "2022-01-23T02:26:03.021510Z",
     "shell.execute_reply": "2022-01-23T02:26:03.020936Z",
     "shell.execute_reply.started": "2022-01-19T11:20:17.036084Z"
    },
    "papermill": {
     "duration": 3.439413,
     "end_time": "2022-01-23T02:26:03.021680",
     "exception": false,
     "start_time": "2022-01-23T02:25:59.582267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from enum import Enum\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from IPython.display import display\n",
    "\n",
    "from joblib import delayed, Parallel\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = '/home/steven/av_data/input'\n",
    "\n",
    "# data configurations\n",
    "USE_PRECOMPUTE_FEATURES = False  # Load precomputed features for train.csv from private dataset (just for speed up)\n",
    "\n",
    "# model & ensemble configurations\n",
    "PREDICT_CNN = True\n",
    "PREDICT_MLP = True\n",
    "PREDICT_GBDT = True\n",
    "PREDICT_TABNET = False\n",
    "\n",
    "GBDT_NUM_MODELS = 5 #3\n",
    "GBDT_LR = 0.02  # 0.1\n",
    "\n",
    "NN_VALID_TH = 0.185\n",
    "NN_MODEL_TOP_N = 3\n",
    "TAB_MODEL_TOP_N = 3\n",
    "ENSEMBLE_METHOD = 'mean'\n",
    "NN_NUM_MODELS = 10\n",
    "TABNET_NUM_MODELS = 5\n",
    "\n",
    "# for saving quota\n",
    "IS_1ST_STAGE = False\n",
    "SHORTCUT_NN_IN_1ST_STAGE = False  # early-stop training to save GPU quota\n",
    "SHORTCUT_GBDT_IN_1ST_STAGE = False\n",
    "MEMORY_TEST_MODE = False\n",
    "\n",
    "# for ablation studies\n",
    "CV_SPLIT = 'time'  # 'time': time-series KFold 'group': GroupKFold by stock-id\n",
    "USE_PRICE_NN_FEATURES = True  # Use nearest neighbor features that rely on tick size\n",
    "USE_VOL_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_SIZE_NN_FEATURES = True  # Use nearest neighbor features that can be calculated without tick size\n",
    "USE_RANDOM_NN_FEATURES = False  # Use random index to aggregate neighbors\n",
    "\n",
    "USE_TIME_ID_NN = True  # Use time-id based neighbors\n",
    "USE_STOCK_ID_NN = True  # Use stock-id based neighbors\n",
    "\n",
    "ENABLE_RANK_NORMALIZATION = True  # Enable rank-normalization\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    elapsed = time.time() - s\n",
    "    print(f'[{name}] {elapsed: .3f}sec')\n",
    "    \n",
    "def print_trace(name: str = ''):\n",
    "    print(f'ERROR RAISED IN {name or \"anonymous\"}')\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:03.083062Z",
     "iopub.status.busy": "2022-01-23T02:26:03.082368Z",
     "iopub.status.idle": "2022-01-23T02:26:30.045911Z",
     "shell.execute_reply": "2022-01-23T02:26:30.045272Z",
     "shell.execute_reply.started": "2022-01-19T11:20:20.281019Z"
    },
    "papermill": {
     "duration": 26.995924,
     "end_time": "2022-01-23T02:26:30.046046",
     "exception": false,
     "start_time": "2022-01-23T02:26:03.050122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install /home/steven/av_data/input/pytorchtabnet/pytorch_tabnet-2.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.9 MB 30.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /home/steven/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.21.5)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-11.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:30.105533Z",
     "iopub.status.busy": "2022-01-23T02:26:30.104748Z",
     "iopub.status.idle": "2022-01-23T02:26:30.415719Z",
     "shell.execute_reply": "2022-01-23T02:26:30.416330Z",
     "shell.execute_reply.started": "2022-01-19T11:20:47.625381Z"
    },
    "papermill": {
     "duration": 0.341799,
     "end_time": "2022-01-23T02:26:30.416539",
     "exception": false,
     "start_time": "2022-01-23T02:26:30.074740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', 'train.csv'))\n",
    "stock_ids = set(train['stock_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030693,
     "end_time": "2022-01-23T02:26:30.479103",
     "exception": false,
     "start_time": "2022-01-23T02:26:30.448410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Base Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:30.573125Z",
     "iopub.status.busy": "2022-01-23T02:26:30.553308Z",
     "iopub.status.idle": "2022-01-23T02:26:30.575466Z",
     "shell.execute_reply": "2022-01-23T02:26:30.575064Z",
     "shell.execute_reply.started": "2022-01-19T11:20:47.920189Z"
    },
    "papermill": {
     "duration": 0.067985,
     "end_time": "2022-01-23T02:26:30.575573",
     "exception": false,
     "start_time": "2022-01-23T02:26:30.507588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataBlock(Enum):\n",
    "    TRAIN = 1\n",
    "    TEST = 2\n",
    "    BOTH = 3\n",
    "\n",
    "\n",
    "def load_stock_data(stock_id: int, directory: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', directory, f'stock_id={stock_id}'))\n",
    "\n",
    "\n",
    "def load_data(stock_id: int, stem: str, block: DataBlock) -> pd.DataFrame:\n",
    "    if block == DataBlock.TRAIN:\n",
    "        return load_stock_data(stock_id, f'{stem}_train.parquet')\n",
    "    elif block == DataBlock.TEST:\n",
    "        return load_stock_data(stock_id, f'{stem}_test.parquet')\n",
    "    else:\n",
    "        return pd.concat([\n",
    "            load_data(stock_id, stem, DataBlock.TRAIN),\n",
    "            load_data(stock_id, stem, DataBlock.TEST)\n",
    "        ]).reset_index(drop=True)\n",
    "\n",
    "def load_book(stock_id: int, block: DataBlock=DataBlock.TRAIN) -> pd.DataFrame:\n",
    "    return load_data(stock_id, 'book', block)\n",
    "\n",
    "\n",
    "def load_trade(stock_id: int, block=DataBlock.TRAIN) -> pd.DataFrame:\n",
    "    return load_data(stock_id, 'trade', block)\n",
    "\n",
    "\n",
    "def calc_wap1(df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "\n",
    "def calc_wap2(df: pd.DataFrame) -> pd.Series:\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "\n",
    "def realized_volatility(series):\n",
    "    return np.sqrt(np.sum(series**2))\n",
    "\n",
    "\n",
    "def log_return(series: np.ndarray):\n",
    "    return np.log(series).diff()\n",
    "\n",
    "\n",
    "def log_return_df2(series: np.ndarray):\n",
    "    return np.log(series).diff(2)\n",
    "\n",
    "\n",
    "def flatten_name(prefix, src_names):\n",
    "    ret = []\n",
    "    for c in src_names:\n",
    "        if c[0] in ['time_id', 'stock_id']:\n",
    "            ret.append(c[0])\n",
    "        else:\n",
    "            ret.append('.'.join([prefix] + list(c)))\n",
    "    return ret\n",
    "\n",
    "\n",
    "def make_book_feature(stock_id, block = DataBlock.TRAIN):\n",
    "    book = load_book(stock_id, block)\n",
    "\n",
    "    book['wap1'] = calc_wap1(book)\n",
    "    book['wap2'] = calc_wap2(book)\n",
    "    book['log_return1'] = book.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    book['log_return2'] = book.groupby(['time_id'])['wap2'].apply(log_return)\n",
    "    book['log_return_ask1'] = book.groupby(['time_id'])['ask_price1'].apply(log_return)\n",
    "    book['log_return_ask2'] = book.groupby(['time_id'])['ask_price2'].apply(log_return)\n",
    "    book['log_return_bid1'] = book.groupby(['time_id'])['bid_price1'].apply(log_return)\n",
    "    book['log_return_bid2'] = book.groupby(['time_id'])['bid_price2'].apply(log_return)\n",
    "\n",
    "    book['wap_balance'] = abs(book['wap1'] - book['wap2'])\n",
    "    book['price_spread'] = (book['ask_price1'] - book['bid_price1']) / ((book['ask_price1'] + book['bid_price1']) / 2)\n",
    "    book['bid_spread'] = book['bid_price1'] - book['bid_price2']\n",
    "    book['ask_spread'] = book['ask_price1'] - book['ask_price2']\n",
    "    book['total_volume'] = (book['ask_size1'] + book['ask_size2']) + (book['bid_size1'] + book['bid_size2'])\n",
    "    book['volume_imbalance'] = abs((book['ask_size1'] + book['ask_size2']) - (book['bid_size1'] + book['bid_size2']))\n",
    "    \n",
    "    features = {\n",
    "        'seconds_in_bucket': ['count'],\n",
    "        'wap1': [np.sum, np.mean, np.std],\n",
    "        'wap2': [np.sum, np.mean, np.std],\n",
    "        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_ask1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_ask2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_bid1': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'log_return_bid2': [np.sum, realized_volatility, np.mean, np.std],\n",
    "        'wap_balance': [np.sum, np.mean, np.std],\n",
    "        'price_spread':[np.sum, np.mean, np.std],\n",
    "        'bid_spread':[np.sum, np.mean, np.std],\n",
    "        'ask_spread':[np.sum, np.mean, np.std],\n",
    "        'total_volume':[np.sum, np.mean, np.std],\n",
    "        'volume_imbalance':[np.sum, np.mean, np.std]\n",
    "    }\n",
    "    \n",
    "    agg = book.groupby('time_id').agg(features).reset_index(drop=False)\n",
    "    agg.columns = flatten_name('book', agg.columns)\n",
    "    agg['stock_id'] = stock_id\n",
    "    \n",
    "    for time in [450, 300, 150]:\n",
    "        d = book[book['seconds_in_bucket'] >= time].groupby('time_id').agg(features).reset_index(drop=False)\n",
    "        d.columns = flatten_name(f'book_{time}', d.columns)\n",
    "        agg = pd.merge(agg, d, on='time_id', how='left')\n",
    "    return agg\n",
    "\n",
    "\n",
    "def make_trade_feature(stock_id, block = DataBlock.TRAIN):\n",
    "    trade = load_trade(stock_id, block)\n",
    "    trade['log_return'] = trade.groupby('time_id')['price'].apply(log_return)\n",
    "\n",
    "    features = {\n",
    "        'log_return':[realized_volatility],\n",
    "        'seconds_in_bucket':['count'],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "    }\n",
    "\n",
    "    agg = trade.groupby('time_id').agg(features).reset_index()\n",
    "    agg.columns = flatten_name('trade', agg.columns)\n",
    "    agg['stock_id'] = stock_id\n",
    "        \n",
    "    for time in [450, 300, 150]:\n",
    "        d = trade[trade['seconds_in_bucket'] >= time].groupby('time_id').agg(features).reset_index(drop=False)\n",
    "        d.columns = flatten_name(f'trade_{time}', d.columns)\n",
    "        agg = pd.merge(agg, d, on='time_id', how='left')\n",
    "    return agg\n",
    "\n",
    "\n",
    "def make_book_feature_v2(stock_id, block = DataBlock.TRAIN):\n",
    "    book = load_book(stock_id, block)\n",
    "\n",
    "    prices = book.set_index('time_id')[['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2']]\n",
    "    time_ids = list(set(prices.index))\n",
    "\n",
    "    ticks = {}\n",
    "    for tid in time_ids:\n",
    "        try:\n",
    "            price_list = prices.loc[tid].values.flatten()\n",
    "            price_diff = sorted(np.diff(sorted(set(price_list))))\n",
    "            ticks[tid] = price_diff[0]\n",
    "        except Exception:\n",
    "            print_trace(f'tid={tid}')\n",
    "            ticks[tid] = np.nan\n",
    "        \n",
    "    dst = pd.DataFrame()\n",
    "    dst['time_id'] = np.unique(book['time_id'])\n",
    "    dst['stock_id'] = stock_id\n",
    "    dst['tick_size'] = dst['time_id'].map(ticks)\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "def make_features(base, block):\n",
    "    stock_ids = set(base['stock_id'])\n",
    "    with timer('books'):\n",
    "        books = Parallel(n_jobs=-1)(delayed(make_book_feature)(i, block) for i in stock_ids)\n",
    "        book = pd.concat(books)\n",
    "\n",
    "    with timer('trades'):\n",
    "        trades = Parallel(n_jobs=-1)(delayed(make_trade_feature)(i, block) for i in stock_ids)\n",
    "        trade = pd.concat(trades)\n",
    "\n",
    "    with timer('extra features'):\n",
    "        df = pd.merge(base, book, on=['stock_id', 'time_id'], how='left')\n",
    "        df = pd.merge(df, trade, on=['stock_id', 'time_id'], how='left')\n",
    "        #df = make_extra_features(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_features_v2(base, block):\n",
    "    stock_ids = set(base['stock_id'])\n",
    "    with timer('books(v2)'):\n",
    "        books = Parallel(n_jobs=-1)(delayed(make_book_feature_v2)(i, block) for i in stock_ids)\n",
    "        book_v2 = pd.concat(books)\n",
    "\n",
    "    d = pd.merge(base, book_v2, on=['stock_id', 'time_id'], how='left')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:30.639029Z",
     "iopub.status.busy": "2022-01-23T02:26:30.638303Z",
     "iopub.status.idle": "2022-01-23T02:26:41.422225Z",
     "shell.execute_reply": "2022-01-23T02:26:41.421651Z",
     "shell.execute_reply.started": "2022-01-19T11:20:47.961136Z"
    },
    "papermill": {
     "duration": 10.818325,
     "end_time": "2022-01-23T02:26:41.422361",
     "exception": false,
     "start_time": "2022-01-23T02:26:30.604036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[books]  291.941sec\n",
      "[trades]  45.119sec\n",
      "[extra features]  0.734sec\n",
      "[books(v2)]  19.539sec\n",
      "is 1st stage\n",
      "[books]  0.070sec\n",
      "[trades]  0.025sec\n",
      "[extra features]  0.004sec\n",
      "[books(v2)]  0.008sec\n",
      "(428932, 216)\n",
      "(3, 216)\n"
     ]
    }
   ],
   "source": [
    "if USE_PRECOMPUTE_FEATURES:\n",
    "    with timer('load feather'):\n",
    "        df = pd.read_feather(os.path.join(DATA_DIR, 'optiver-df2', 'features_v2.f'))\n",
    "else:\n",
    "    df = make_features(train, DataBlock.TRAIN)\n",
    "    # v2\n",
    "    df = make_features_v2(df, DataBlock.TRAIN)\n",
    "\n",
    "df.to_feather('features_v2.f')  # save cache\n",
    "\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', 'test.csv'))\n",
    "if len(test) == 3:\n",
    "    print('is 1st stage')\n",
    "    IS_1ST_STAGE = True\n",
    "\n",
    "if IS_1ST_STAGE and MEMORY_TEST_MODE:\n",
    "    print('use copy of training data as test data to immitate 2nd stage RAM usage.')\n",
    "    test_df = df.iloc[:170000].copy()\n",
    "    test_df['time_id'] += 32767\n",
    "    test_df['row_id'] = ''\n",
    "else:\n",
    "    test_df = make_features(test, DataBlock.TEST)\n",
    "    test_df = make_features_v2(test_df, DataBlock.TEST)\n",
    "\n",
    "print(df.shape)\n",
    "print(test_df.shape)\n",
    "df = pd.concat([df, test_df.drop('row_id', axis=1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028421,
     "end_time": "2022-01-23T02:26:41.480303",
     "exception": false,
     "start_time": "2022-01-23T02:26:41.451882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Nearest-Neighbor Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:41.555136Z",
     "iopub.status.busy": "2022-01-23T02:26:41.550462Z",
     "iopub.status.idle": "2022-01-23T02:26:41.557458Z",
     "shell.execute_reply": "2022-01-23T02:26:41.557058Z",
     "shell.execute_reply.started": "2022-01-19T11:20:58.104849Z"
    },
    "papermill": {
     "duration": 0.048663,
     "end_time": "2022-01-23T02:26:41.557564",
     "exception": false,
     "start_time": "2022-01-23T02:26:41.508901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_NEIGHBORS_MAX = 80\n",
    "\n",
    "class Neighbors:\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 pivot: pd.DataFrame, \n",
    "                 p: float, \n",
    "                 metric: str = 'minkowski', \n",
    "                 metric_params: Optional[Dict] = None, \n",
    "                 exclude_self: bool = False):\n",
    "        self.name = name\n",
    "        self.exclude_self = exclude_self\n",
    "        self.p = p\n",
    "        self.metric = metric\n",
    "        \n",
    "        if metric == 'random':\n",
    "            n_queries = len(pivot)\n",
    "            self.neighbors = np.random.randint(n_queries, size=(n_queries, N_NEIGHBORS_MAX))\n",
    "        else:\n",
    "            nn = NearestNeighbors(\n",
    "                n_neighbors=N_NEIGHBORS_MAX, \n",
    "                p=p, \n",
    "                metric=metric, \n",
    "                metric_params=metric_params\n",
    "            )\n",
    "            nn.fit(pivot)\n",
    "            _, self.neighbors = nn.kneighbors(pivot, return_distance=True)\n",
    "\n",
    "        self.columns = self.index = self.feature_values = self.feature_col = None\n",
    "\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def make_nn_feature(self, n=5, agg=np.mean) -> pd.DataFrame:\n",
    "        assert self.feature_values is not None, \"should call rearrange_feature_values beforehand\"\n",
    "\n",
    "        start = 1 if self.exclude_self else 0\n",
    "\n",
    "        pivot_aggs = pd.DataFrame(\n",
    "            agg(self.feature_values[start:n,:,:], axis=0), \n",
    "            columns=self.columns, \n",
    "            index=self.index\n",
    "        )\n",
    "\n",
    "        dst = pivot_aggs.unstack().reset_index()\n",
    "        dst.columns = ['stock_id', 'time_id', f'{self.feature_col}_nn{n}_{self.name}_{agg.__name__}']\n",
    "        return dst\n",
    "\n",
    "\n",
    "class TimeIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        feature_pivot = df.pivot('time_id', 'stock_id', feature_col)\n",
    "        feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "        feature_pivot.head()\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, *feature_pivot.shape))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, :] += feature_pivot.values[self.neighbors[:, i], :]\n",
    "\n",
    "        self.columns = list(feature_pivot.columns)\n",
    "        self.index = list(feature_pivot.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"time-id NN (name={self.name}, metric={self.metric}, p={self.p})\"\n",
    "\n",
    "\n",
    "class StockIdNeighbors(Neighbors):\n",
    "    def rearrange_feature_values(self, df: pd.DataFrame, feature_col: str) -> None:\n",
    "        \"\"\"stock-id based nearest neighbor features\"\"\"\n",
    "        feature_pivot = df.pivot('time_id', 'stock_id', feature_col)\n",
    "        feature_pivot = feature_pivot.fillna(feature_pivot.mean())\n",
    "\n",
    "        feature_values = np.zeros((N_NEIGHBORS_MAX, *feature_pivot.shape))\n",
    "\n",
    "        for i in range(N_NEIGHBORS_MAX):\n",
    "            feature_values[i, :, :] += feature_pivot.values[:, self.neighbors[:, i]]\n",
    "\n",
    "        self.columns = list(feature_pivot.columns)\n",
    "        self.index = list(feature_pivot.index)\n",
    "        self.feature_values = feature_values\n",
    "        self.feature_col = feature_col\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        return f\"stock-id NN (name={self.name}, metric={self.metric}, p={self.p})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:41.619972Z",
     "iopub.status.busy": "2022-01-23T02:26:41.619012Z",
     "iopub.status.idle": "2022-01-23T02:26:41.982083Z",
     "shell.execute_reply": "2022-01-23T02:26:41.981564Z",
     "shell.execute_reply.started": "2022-01-19T11:20:58.127333Z"
    },
    "papermill": {
     "duration": 0.395558,
     "end_time": "2022-01-23T02:26:41.982243",
     "exception": false,
     "start_time": "2022-01-23T02:26:41.586685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the tau itself is meaningless for GBDT, but useful as input to aggregate in Nearest Neighbor features\n",
    "df['trade.tau'] = np.sqrt(1 / df['trade.seconds_in_bucket.count'])\n",
    "df['trade_150.tau'] = np.sqrt(1 / df['trade_150.seconds_in_bucket.count'])\n",
    "df['book.tau'] = np.sqrt(1 / df['book.seconds_in_bucket.count'])\n",
    "df['real_price'] = 0.01 / df['tick_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-16T02:18:50.195022Z",
     "iopub.status.busy": "2022-01-16T02:18:50.1946Z",
     "iopub.status.idle": "2022-01-16T02:18:50.201136Z",
     "shell.execute_reply": "2022-01-16T02:18:50.199965Z",
     "shell.execute_reply.started": "2022-01-16T02:18:50.194964Z"
    },
    "papermill": {
     "duration": 0.030837,
     "end_time": "2022-01-23T02:26:42.050294",
     "exception": false,
     "start_time": "2022-01-23T02:26:42.019457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Build Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:26:42.123778Z",
     "iopub.status.busy": "2022-01-23T02:26:42.122544Z",
     "iopub.status.idle": "2022-01-23T02:33:32.953387Z",
     "shell.execute_reply": "2022-01-23T02:33:32.953798Z",
     "shell.execute_reply.started": "2022-01-19T11:20:58.499414Z"
    },
    "papermill": {
     "duration": 410.874751,
     "end_time": "2022-01-23T02:33:32.953989",
     "exception": false,
     "start_time": "2022-01-23T02:26:42.079238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[knn fit]  128.394sec\n"
     ]
    }
   ],
   "source": [
    "time_id_neighbors: List[Neighbors] = []\n",
    "stock_id_neighbors: List[Neighbors] = []\n",
    "\n",
    "with timer('knn fit'):\n",
    "    df_pv = df[['stock_id', 'time_id']].copy()\n",
    "    df_pv['price'] = 0.01 / df['tick_size']\n",
    "    df_pv['vol'] = df['book.log_return1.realized_volatility']\n",
    "    df_pv['trade.tau'] = df['trade.tau']\n",
    "    df_pv['trade.size.sum'] = df['book.total_volume.sum']\n",
    "\n",
    "    if USE_PRICE_NN_FEATURES:\n",
    "        pivot = df_pv.pivot('time_id', 'stock_id', 'price')\n",
    "        pivot = pivot.fillna(pivot.mean())\n",
    "        pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'time_price_c', \n",
    "                pivot, \n",
    "                p=2, \n",
    "                metric='canberra', \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'time_price_m', \n",
    "                pivot, \n",
    "                p=2, \n",
    "                metric='mahalanobis',\n",
    "                metric_params={'VI':np.cov(pivot.values.T)}\n",
    "            )\n",
    "        )\n",
    "        stock_id_neighbors.append(\n",
    "            StockIdNeighbors(\n",
    "                'stock_price_l1', \n",
    "                minmax_scale(pivot.transpose()), \n",
    "                p=1, \n",
    "                exclude_self=True)\n",
    "        )\n",
    "\n",
    "    if USE_VOL_NN_FEATURES:\n",
    "        pivot = df_pv.pivot('time_id', 'stock_id', 'vol')\n",
    "        pivot = pivot.fillna(pivot.mean())\n",
    "        pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors('time_vol_l1', pivot, p=1)\n",
    "        )\n",
    "        stock_id_neighbors.append(\n",
    "            StockIdNeighbors(\n",
    "                'stock_vol_l1', \n",
    "                minmax_scale(pivot.transpose()), \n",
    "                p=1, \n",
    "                exclude_self=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if USE_SIZE_NN_FEATURES:\n",
    "        pivot = df_pv.pivot('time_id', 'stock_id', 'trade.size.sum')\n",
    "        pivot = pivot.fillna(pivot.mean())\n",
    "        pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'time_size_m', \n",
    "                pivot, \n",
    "                p=2, \n",
    "                metric='mahalanobis', \n",
    "                metric_params={'VI':np.cov(pivot.values.T)}\n",
    "            )\n",
    "        )\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'time_size_c', \n",
    "                pivot, \n",
    "                p=2, \n",
    "                metric='canberra'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    if USE_RANDOM_NN_FEATURES:\n",
    "        pivot = df_pv.pivot('time_id', 'stock_id', 'vol')\n",
    "        pivot = pivot.fillna(pivot.mean())\n",
    "        pivot = pd.DataFrame(minmax_scale(pivot))\n",
    "\n",
    "        time_id_neighbors.append(\n",
    "            TimeIdNeighbors(\n",
    "                'time_random', \n",
    "                pivot, \n",
    "                p=2, \n",
    "                metric='random'\n",
    "            )\n",
    "        )\n",
    "        stock_id_neighbors.append(\n",
    "            StockIdNeighbors(\n",
    "                'stock_random', \n",
    "                pivot.transpose(), \n",
    "                p=2,\n",
    "                metric='random')\n",
    "        )\n",
    "\n",
    "\n",
    "if not USE_TIME_ID_NN:\n",
    "    time_id_neighbors = []\n",
    "    \n",
    "if not USE_STOCK_ID_NN:\n",
    "    stock_id_neighbors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028479,
     "end_time": "2022-01-23T02:33:33.011086",
     "exception": false,
     "start_time": "2022-01-23T02:33:32.982607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Check Neighbor Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.073803Z",
     "iopub.status.busy": "2022-01-23T02:33:33.073080Z",
     "iopub.status.idle": "2022-01-23T02:33:33.075920Z",
     "shell.execute_reply": "2022-01-23T02:33:33.075471Z",
     "shell.execute_reply.started": "2022-01-19T11:27:55.548287Z"
    },
    "papermill": {
     "duration": 0.035942,
     "end_time": "2022-01-23T02:33:33.076032",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.040090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_rank_correraltion(neighbors, top_n=5):\n",
    "    if not neighbors:\n",
    "        return\n",
    "    neighbor_indices = pd.DataFrame()\n",
    "    for n in neighbors:\n",
    "        neighbor_indices[n.name] = n.neighbors[:,:top_n].flatten()\n",
    "\n",
    "    sns.heatmap(neighbor_indices.corr('kendall'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.138908Z",
     "iopub.status.busy": "2022-01-23T02:33:33.138122Z",
     "iopub.status.idle": "2022-01-23T02:33:33.192860Z",
     "shell.execute_reply": "2022-01-23T02:33:33.192422Z",
     "shell.execute_reply.started": "2022-01-19T11:27:55.555683Z"
    },
    "papermill": {
     "duration": 0.08837,
     "end_time": "2022-01-23T02:33:33.192975",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.104605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-id NN (name=time_price_c, metric=canberra, p=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_6</th>\n",
       "      <th>top_7</th>\n",
       "      <th>top_8</th>\n",
       "      <th>top_9</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>30183</td>\n",
       "      <td>31471</td>\n",
       "      <td>26708</td>\n",
       "      <td>7864</td>\n",
       "      <td>22752</td>\n",
       "      <td>10619</td>\n",
       "      <td>11453</td>\n",
       "      <td>1205</td>\n",
       "      <td>9352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2811</td>\n",
       "      <td>29583</td>\n",
       "      <td>30798</td>\n",
       "      <td>17639</td>\n",
       "      <td>25131</td>\n",
       "      <td>23202</td>\n",
       "      <td>14857</td>\n",
       "      <td>4739</td>\n",
       "      <td>3399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5829</td>\n",
       "      <td>4275</td>\n",
       "      <td>7783</td>\n",
       "      <td>4487</td>\n",
       "      <td>7845</td>\n",
       "      <td>25439</td>\n",
       "      <td>17530</td>\n",
       "      <td>18634</td>\n",
       "      <td>19747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>6367</td>\n",
       "      <td>19386</td>\n",
       "      <td>1255</td>\n",
       "      <td>12559</td>\n",
       "      <td>19472</td>\n",
       "      <td>18358</td>\n",
       "      <td>31719</td>\n",
       "      <td>6481</td>\n",
       "      <td>26475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>31554</td>\n",
       "      <td>24443</td>\n",
       "      <td>5916</td>\n",
       "      <td>19164</td>\n",
       "      <td>20430</td>\n",
       "      <td>659</td>\n",
       "      <td>31077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_1  top_2  top_3  top_4  top_5  top_6  top_7  top_8  top_9  top_10\n",
       "time_id                                                                       \n",
       "5            5  30183  31471  26708   7864  22752  10619  11453   1205    9352\n",
       "11          11   2811  29583  30798  17639  25131  23202  14857   4739    3399\n",
       "16          16   5829   4275   7783   4487   7845  25439  17530  18634   19747\n",
       "31          31   6367  19386   1255  12559  19472  18358  31719   6481   26475\n",
       "32          32     34      4  31554  24443   5916  19164  20430    659   31077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-id NN (name=time_price_m, metric=mahalanobis, p=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_6</th>\n",
       "      <th>top_7</th>\n",
       "      <th>top_8</th>\n",
       "      <th>top_9</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>31471</td>\n",
       "      <td>11453</td>\n",
       "      <td>30183</td>\n",
       "      <td>7864</td>\n",
       "      <td>26708</td>\n",
       "      <td>4091</td>\n",
       "      <td>30430</td>\n",
       "      <td>22752</td>\n",
       "      <td>9889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2811</td>\n",
       "      <td>29583</td>\n",
       "      <td>30798</td>\n",
       "      <td>14857</td>\n",
       "      <td>4739</td>\n",
       "      <td>17639</td>\n",
       "      <td>25131</td>\n",
       "      <td>23202</td>\n",
       "      <td>13745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>4275</td>\n",
       "      <td>18634</td>\n",
       "      <td>5829</td>\n",
       "      <td>25439</td>\n",
       "      <td>17530</td>\n",
       "      <td>7783</td>\n",
       "      <td>4034</td>\n",
       "      <td>4487</td>\n",
       "      <td>19747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>12559</td>\n",
       "      <td>17429</td>\n",
       "      <td>26475</td>\n",
       "      <td>31719</td>\n",
       "      <td>18358</td>\n",
       "      <td>6481</td>\n",
       "      <td>7897</td>\n",
       "      <td>12348</td>\n",
       "      <td>9456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>5916</td>\n",
       "      <td>31554</td>\n",
       "      <td>19164</td>\n",
       "      <td>6213</td>\n",
       "      <td>659</td>\n",
       "      <td>25636</td>\n",
       "      <td>24443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_1  top_2  top_3  top_4  top_5  top_6  top_7  top_8  top_9  top_10\n",
       "time_id                                                                       \n",
       "5            5  31471  11453  30183   7864  26708   4091  30430  22752    9889\n",
       "11          11   2811  29583  30798  14857   4739  17639  25131  23202   13745\n",
       "16          16   4275  18634   5829  25439  17530   7783   4034   4487   19747\n",
       "31          31  12559  17429  26475  31719  18358   6481   7897  12348    9456\n",
       "32          32     34      4   5916  31554  19164   6213    659  25636   24443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-id NN (name=time_vol_l1, metric=minkowski, p=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_6</th>\n",
       "      <th>top_7</th>\n",
       "      <th>top_8</th>\n",
       "      <th>top_9</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>9352</td>\n",
       "      <td>15276</td>\n",
       "      <td>13791</td>\n",
       "      <td>1205</td>\n",
       "      <td>12923</td>\n",
       "      <td>26708</td>\n",
       "      <td>2331</td>\n",
       "      <td>2136</td>\n",
       "      <td>10672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>23202</td>\n",
       "      <td>30798</td>\n",
       "      <td>17639</td>\n",
       "      <td>7460</td>\n",
       "      <td>29583</td>\n",
       "      <td>11227</td>\n",
       "      <td>2811</td>\n",
       "      <td>25131</td>\n",
       "      <td>32597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>9060</td>\n",
       "      <td>25179</td>\n",
       "      <td>25439</td>\n",
       "      <td>21777</td>\n",
       "      <td>15727</td>\n",
       "      <td>17530</td>\n",
       "      <td>6476</td>\n",
       "      <td>211</td>\n",
       "      <td>30791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>10291</td>\n",
       "      <td>15689</td>\n",
       "      <td>18848</td>\n",
       "      <td>22824</td>\n",
       "      <td>14449</td>\n",
       "      <td>1142</td>\n",
       "      <td>6367</td>\n",
       "      <td>21148</td>\n",
       "      <td>25731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>25584</td>\n",
       "      <td>26883</td>\n",
       "      <td>5235</td>\n",
       "      <td>2772</td>\n",
       "      <td>26430</td>\n",
       "      <td>2502</td>\n",
       "      <td>22014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_1  top_2  top_3  top_4  top_5  top_6  top_7  top_8  top_9  top_10\n",
       "time_id                                                                       \n",
       "5            5   9352  15276  13791   1205  12923  26708   2331   2136   10672\n",
       "11          11  23202  30798  17639   7460  29583  11227   2811  25131   32597\n",
       "16          16   9060  25179  25439  21777  15727  17530   6476    211   30791\n",
       "31          31  10291  15689  18848  22824  14449   1142   6367  21148   25731\n",
       "32          34     32      4  25584  26883   5235   2772  26430   2502   22014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-id NN (name=time_size_m, metric=mahalanobis, p=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_6</th>\n",
       "      <th>top_7</th>\n",
       "      <th>top_8</th>\n",
       "      <th>top_9</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>30183</td>\n",
       "      <td>23490</td>\n",
       "      <td>22752</td>\n",
       "      <td>26708</td>\n",
       "      <td>20928</td>\n",
       "      <td>13791</td>\n",
       "      <td>1350</td>\n",
       "      <td>31883</td>\n",
       "      <td>10619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>29583</td>\n",
       "      <td>19417</td>\n",
       "      <td>9822</td>\n",
       "      <td>23656</td>\n",
       "      <td>4367</td>\n",
       "      <td>22828</td>\n",
       "      <td>30798</td>\n",
       "      <td>11682</td>\n",
       "      <td>10745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>25439</td>\n",
       "      <td>6121</td>\n",
       "      <td>8168</td>\n",
       "      <td>31443</td>\n",
       "      <td>7845</td>\n",
       "      <td>14721</td>\n",
       "      <td>1040</td>\n",
       "      <td>20630</td>\n",
       "      <td>11497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>13594</td>\n",
       "      <td>16802</td>\n",
       "      <td>20099</td>\n",
       "      <td>31719</td>\n",
       "      <td>1239</td>\n",
       "      <td>19472</td>\n",
       "      <td>3846</td>\n",
       "      <td>12559</td>\n",
       "      <td>13989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>22014</td>\n",
       "      <td>6482</td>\n",
       "      <td>27822</td>\n",
       "      <td>1392</td>\n",
       "      <td>9215</td>\n",
       "      <td>24921</td>\n",
       "      <td>30803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_1  top_2  top_3  top_4  top_5  top_6  top_7  top_8  top_9  top_10\n",
       "time_id                                                                       \n",
       "5            5  30183  23490  22752  26708  20928  13791   1350  31883   10619\n",
       "11          11  29583  19417   9822  23656   4367  22828  30798  11682   10745\n",
       "16          16  25439   6121   8168  31443   7845  14721   1040  20630   11497\n",
       "31          31  13594  16802  20099  31719   1239  19472   3846  12559   13989\n",
       "32          32     34      4  22014   6482  27822   1392   9215  24921   30803"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time-id NN (name=time_size_c, metric=canberra, p=2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_1</th>\n",
       "      <th>top_2</th>\n",
       "      <th>top_3</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_6</th>\n",
       "      <th>top_7</th>\n",
       "      <th>top_8</th>\n",
       "      <th>top_9</th>\n",
       "      <th>top_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>26708</td>\n",
       "      <td>30183</td>\n",
       "      <td>22752</td>\n",
       "      <td>1205</td>\n",
       "      <td>10619</td>\n",
       "      <td>9352</td>\n",
       "      <td>15276</td>\n",
       "      <td>30620</td>\n",
       "      <td>2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2811</td>\n",
       "      <td>17639</td>\n",
       "      <td>29583</td>\n",
       "      <td>25131</td>\n",
       "      <td>28020</td>\n",
       "      <td>17604</td>\n",
       "      <td>9822</td>\n",
       "      <td>4739</td>\n",
       "      <td>30798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>5829</td>\n",
       "      <td>4487</td>\n",
       "      <td>6121</td>\n",
       "      <td>7783</td>\n",
       "      <td>1040</td>\n",
       "      <td>29026</td>\n",
       "      <td>7845</td>\n",
       "      <td>17530</td>\n",
       "      <td>16118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>6367</td>\n",
       "      <td>12559</td>\n",
       "      <td>22519</td>\n",
       "      <td>18358</td>\n",
       "      <td>7897</td>\n",
       "      <td>19472</td>\n",
       "      <td>31522</td>\n",
       "      <td>19386</td>\n",
       "      <td>31719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>15989</td>\n",
       "      <td>11985</td>\n",
       "      <td>3732</td>\n",
       "      <td>26430</td>\n",
       "      <td>3607</td>\n",
       "      <td>10523</td>\n",
       "      <td>4487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_1  top_2  top_3  top_4  top_5  top_6  top_7  top_8  top_9  top_10\n",
       "time_id                                                                       \n",
       "5            5  26708  30183  22752   1205  10619   9352  15276  30620    2683\n",
       "11          11   2811  17639  29583  25131  28020  17604   9822   4739   30798\n",
       "16          16   5829   4487   6121   7783   1040  29026   7845  17530   16118\n",
       "31          31   6367  12559  22519  18358   7897  19472  31522  19386   31719\n",
       "32          32     34      4  15989  11985   3732  26430   3607  10523    4487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_ids = np.array(sorted(df['time_id'].unique()))\n",
    "for neighbor in time_id_neighbors:\n",
    "    print(neighbor)\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            time_ids[neighbor.neighbors[:,:10]], \n",
    "            index=pd.Index(time_ids, name='time_id'), \n",
    "            columns=[f'top_{i+1}' for i in range(10)]\n",
    "        ).iloc[1:6]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.263643Z",
     "iopub.status.busy": "2022-01-23T02:33:33.262935Z",
     "iopub.status.idle": "2022-01-23T02:33:33.276604Z",
     "shell.execute_reply": "2022-01-23T02:33:33.276173Z",
     "shell.execute_reply.started": "2022-01-19T11:39:40.610534Z"
    },
    "papermill": {
     "duration": 0.051151,
     "end_time": "2022-01-23T02:33:33.276704",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.225553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock-id NN (name=stock_price_l1, metric=minkowski, p=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "top_1      64\n",
       "top_2      53\n",
       "top_3      56\n",
       "top_4     124\n",
       "top_5      73\n",
       "top_6      96\n",
       "top_7      30\n",
       "top_8      28\n",
       "top_9      66\n",
       "top_10     33\n",
       "Name: 64, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock-id NN (name=stock_vol_l1, metric=minkowski, p=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "top_1      64\n",
       "top_2      20\n",
       "top_3      93\n",
       "top_4      67\n",
       "top_5      52\n",
       "top_6     107\n",
       "top_7      70\n",
       "top_8     120\n",
       "top_9     102\n",
       "top_10     39\n",
       "Name: 64, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_ids = np.array(sorted(df['stock_id'].unique()))\n",
    "for neighbor in stock_id_neighbors:\n",
    "    print(neighbor)\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            stock_ids[neighbor.neighbors[:,:10]], \n",
    "            index=pd.Index(stock_ids, name='stock_id'), \n",
    "            columns=[f'top_{i+1}' for i in range(10)]\n",
    "        ).loc[64]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:33.348457Z",
     "iopub.status.busy": "2022-01-23T02:33:33.347681Z",
     "iopub.status.idle": "2022-01-23T02:33:33.901994Z",
     "shell.execute_reply": "2022-01-23T02:33:33.902453Z",
     "shell.execute_reply.started": "2022-01-18T14:13:43.542166Z"
    },
    "papermill": {
     "duration": 0.591893,
     "end_time": "2022-01-23T02:33:33.902600",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.310707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_rank_correraltion(time_id_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:34.038369Z",
     "iopub.status.busy": "2022-01-23T02:33:34.037754Z",
     "iopub.status.idle": "2022-01-23T02:33:34.275994Z",
     "shell.execute_reply": "2022-01-23T02:33:34.276373Z",
     "shell.execute_reply.started": "2022-01-18T14:13:43.949648Z"
    },
    "papermill": {
     "duration": 0.313195,
     "end_time": "2022-01-23T02:33:34.276516",
     "exception": false,
     "start_time": "2022-01-23T02:33:33.963321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "calculate_rank_correraltion(stock_id_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035477,
     "end_time": "2022-01-23T02:33:34.347529",
     "exception": false,
     "start_time": "2022-01-23T02:33:34.312052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Aggregate Features With Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:34.427036Z",
     "iopub.status.busy": "2022-01-23T02:33:34.426197Z",
     "iopub.status.idle": "2022-01-23T02:33:36.057149Z",
     "shell.execute_reply": "2022-01-23T02:33:36.056625Z",
     "shell.execute_reply.started": "2022-01-18T14:13:44.189634Z"
    },
    "papermill": {
     "duration": 1.674163,
     "end_time": "2022-01-23T02:33:36.057283",
     "exception": false,
     "start_time": "2022-01-23T02:33:34.383120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features with large changes over time are converted to relative ranks within time-id\n",
    "if ENABLE_RANK_NORMALIZATION:\n",
    "    df['trade.order_count.mean'] = df.groupby('time_id')['trade.order_count.mean'].rank()\n",
    "    df['book.total_volume.sum']  = df.groupby('time_id')['book.total_volume.sum'].rank()\n",
    "    df['book.total_volume.mean'] = df.groupby('time_id')['book.total_volume.mean'].rank()\n",
    "    df['book.total_volume.std']  = df.groupby('time_id')['book.total_volume.std'].rank()\n",
    "\n",
    "    df['trade.tau'] = df.groupby('time_id')['trade.tau'].rank()\n",
    "\n",
    "    for dt in [150, 300, 450]:\n",
    "        df[f'book_{dt}.total_volume.sum']  = df.groupby('time_id')[f'book_{dt}.total_volume.sum'].rank()\n",
    "        df[f'book_{dt}.total_volume.mean'] = df.groupby('time_id')[f'book_{dt}.total_volume.mean'].rank()\n",
    "        df[f'book_{dt}.total_volume.std']  = df.groupby('time_id')[f'book_{dt}.total_volume.std'].rank()\n",
    "        df[f'trade_{dt}.order_count.mean'] = df.groupby('time_id')[f'trade_{dt}.order_count.mean'].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:36.151666Z",
     "iopub.status.busy": "2022-01-23T02:33:36.150004Z",
     "iopub.status.idle": "2022-01-23T02:33:36.152354Z",
     "shell.execute_reply": "2022-01-23T02:33:36.152748Z",
     "shell.execute_reply.started": "2022-01-18T14:13:44.199422Z"
    },
    "papermill": {
     "duration": 0.059468,
     "end_time": "2022-01-23T02:33:36.152899",
     "exception": false,
     "start_time": "2022-01-23T02:33:36.093431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_nearest_neighbor_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df2 = df.copy()\n",
    "    print(df2.shape)\n",
    "\n",
    "    feature_cols_stock = {\n",
    "        'book.log_return1.realized_volatility': [np.mean, np.min, np.max, np.std],\n",
    "        'trade.seconds_in_bucket.count': [np.mean],\n",
    "        'trade.tau': [np.mean],\n",
    "        'trade_150.tau': [np.mean],\n",
    "        'book.tau': [np.mean],\n",
    "        'trade.size.sum': [np.mean],\n",
    "        'book.seconds_in_bucket.count': [np.mean],\n",
    "    }\n",
    "    \n",
    "    feature_cols = {\n",
    "        'book.log_return1.realized_volatility': [np.mean, np.min, np.max, np.std],\n",
    "        'real_price': [np.max, np.mean, np.min],\n",
    "        'trade.seconds_in_bucket.count': [np.mean],\n",
    "        'trade.tau': [np.mean],\n",
    "        'trade.size.sum': [np.mean],\n",
    "        'book.seconds_in_bucket.count': [np.mean],\n",
    "        'trade_150.tau_nn20_stock_vol_l1_mean': [np.mean],\n",
    "        'trade.size.sum_nn20_stock_vol_l1_mean': [np.mean],\n",
    "    }\n",
    "\n",
    "    time_id_neigbor_sizes = [3, 5, 10, 20, 40]\n",
    "    time_id_neigbor_sizes_vol = [2, 3, 5, 10, 20, 40]\n",
    "    stock_id_neighbor_sizes = [10, 20, 40]\n",
    "\n",
    "    ndf: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def _add_ndf(ndf: Optional[pd.DataFrame], dst: pd.DataFrame) -> pd.DataFrame:\n",
    "        if ndf is None:\n",
    "            return dst\n",
    "        else:\n",
    "            ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
    "            return ndf\n",
    "\n",
    "    # neighbor stock_id\n",
    "    for feature_col in feature_cols_stock.keys():\n",
    "        try:\n",
    "            if feature_col not in df2.columns:\n",
    "                print(f\"column {feature_col} is skipped\")\n",
    "                continue\n",
    "\n",
    "            if not stock_id_neighbors:\n",
    "                continue\n",
    "\n",
    "            for nn in stock_id_neighbors:\n",
    "                nn.rearrange_feature_values(df2, feature_col)\n",
    "\n",
    "            for agg in feature_cols_stock[feature_col]:\n",
    "                for n in stock_id_neighbor_sizes:\n",
    "                    try:\n",
    "                        for nn in stock_id_neighbors:\n",
    "                            dst = nn.make_nn_feature(n, agg)\n",
    "                            ndf = _add_ndf(ndf, dst)\n",
    "                    except Exception:\n",
    "                        print_trace('stock-id nn')\n",
    "                        pass\n",
    "        except Exception:\n",
    "            print_trace('stock-id nn')\n",
    "            pass\n",
    "\n",
    "    if ndf is not None:\n",
    "        df2 = pd.merge(df2, ndf, on=['time_id', 'stock_id'], how='left')\n",
    "    ndf = None\n",
    "\n",
    "    print(df2.shape)\n",
    "\n",
    "    # neighbor time_id\n",
    "    for feature_col in feature_cols.keys():\n",
    "        try:\n",
    "            if not USE_PRICE_NN_FEATURES and feature_col == 'real_price':\n",
    "                continue\n",
    "            if feature_col not in df2.columns:\n",
    "                print(f\"column {feature_col} is skipped\")\n",
    "                continue\n",
    "\n",
    "            for nn in time_id_neighbors:\n",
    "                nn.rearrange_feature_values(df2, feature_col)\n",
    "\n",
    "            if 'volatility' in feature_col:\n",
    "                time_id_ns = time_id_neigbor_sizes_vol\n",
    "            else:\n",
    "                time_id_ns = time_id_neigbor_sizes\n",
    "\n",
    "            for agg in feature_cols[feature_col]:\n",
    "                for n in time_id_ns:\n",
    "                    try:\n",
    "                        for nn in time_id_neighbors:\n",
    "                            dst = nn.make_nn_feature(n, agg)\n",
    "                            ndf = _add_ndf(ndf, dst)\n",
    "                    except Exception:\n",
    "                        print_trace('time-id nn')\n",
    "                        pass\n",
    "        except Exception:\n",
    "            print_trace('time-id nn')\n",
    "\n",
    "    if ndf is not None:\n",
    "        df2 = pd.merge(df2, ndf, on=['time_id', 'stock_id'], how='left')\n",
    "\n",
    "    # features further derived from nearest neighbor features\n",
    "    try:\n",
    "        if USE_PRICE_NN_FEATURES:\n",
    "            for sz in time_id_neigbor_sizes:\n",
    "                denominator = f\"real_price_nn{sz}_time_price_c\"\n",
    "\n",
    "                df2[f'real_price_rankmin_{sz}']  = df2['real_price'] / df2[f\"{denominator}_amin\"]\n",
    "                df2[f'real_price_rankmax_{sz}']  = df2['real_price'] / df2[f\"{denominator}_amax\"]\n",
    "                df2[f'real_price_rankmean_{sz}'] = df2['real_price'] / df2[f\"{denominator}_mean\"]\n",
    "\n",
    "            for sz in time_id_neigbor_sizes_vol:\n",
    "                denominator = f\"book.log_return1.realized_volatility_nn{sz}_time_price_c\"\n",
    "\n",
    "                df2[f'vol_rankmin_{sz}'] = \\\n",
    "                    df2['book.log_return1.realized_volatility'] / df2[f\"{denominator}_amin\"]\n",
    "                df2[f'vol_rankmax_{sz}'] = \\\n",
    "                    df2['book.log_return1.realized_volatility'] / df2[f\"{denominator}_amax\"]\n",
    "\n",
    "        price_cols = [c for c in df2.columns if 'real_price' in c and 'rank' not in c]\n",
    "        for c in price_cols:\n",
    "            del df2[c]\n",
    "\n",
    "        if USE_PRICE_NN_FEATURES:\n",
    "            for sz in time_id_neigbor_sizes_vol:\n",
    "                tgt = f'book.log_return1.realized_volatility_nn{sz}_time_price_m_mean'\n",
    "                df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n",
    "    except Exception:\n",
    "        print_trace('nn features')\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:33:36.370271Z",
     "iopub.status.busy": "2022-01-23T02:33:36.368938Z",
     "iopub.status.idle": "2022-01-23T02:34:51.959576Z",
     "shell.execute_reply": "2022-01-23T02:34:51.959095Z",
     "shell.execute_reply.started": "2022-01-18T14:13:44.224929Z"
    },
    "papermill": {
     "duration": 75.77123,
     "end_time": "2022-01-23T02:34:51.959705",
     "exception": false,
     "start_time": "2022-01-23T02:33:36.188475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428935, 220)\n",
      "(428935, 280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  ndf[dst.columns[-1]] = dst[dst.columns[-1]].astype(np.float32)\n",
      "/tmp/ipykernel_3888766/1622911503.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n",
      "/tmp/ipykernel_3888766/1622911503.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n",
      "/tmp/ipykernel_3888766/1622911503.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n",
      "/tmp/ipykernel_3888766/1622911503.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n",
      "/tmp/ipykernel_3888766/1622911503.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n",
      "/tmp/ipykernel_3888766/1622911503.py:128: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'{tgt}_rank'] = df2.groupby('time_id')[tgt].rank()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[make nearest neighbor feature]  23.847sec\n",
      "(428935, 582)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "with timer('make nearest neighbor feature'):\n",
    "    df2 = make_nearest_neighbor_feature(df)\n",
    "\n",
    "print(df2.shape)\n",
    "df2.reset_index(drop=True).to_feather('optiver_df2.f')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037563,
     "end_time": "2022-01-23T02:34:52.038355",
     "exception": false,
     "start_time": "2022-01-23T02:34:52.000792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Misc Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:53.076612Z",
     "iopub.status.busy": "2022-01-23T02:34:53.075859Z",
     "iopub.status.idle": "2022-01-23T02:34:53.335135Z",
     "shell.execute_reply": "2022-01-23T02:34:53.334610Z",
     "shell.execute_reply.started": "2022-01-15T04:54:06.290787Z"
    },
    "papermill": {
     "duration": 1.258742,
     "end_time": "2022-01-23T02:34:53.335258",
     "exception": false,
     "start_time": "2022-01-23T02:34:52.076516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skew correction for NN\n",
    "cols_to_log = [\n",
    "    'trade.size.sum',\n",
    "    'trade_150.size.sum',\n",
    "    'trade_300.size.sum',\n",
    "    'trade_450.size.sum',\n",
    "    'volume_imbalance'\n",
    "]\n",
    "for c in df2.columns:\n",
    "    for check in cols_to_log:\n",
    "        try:\n",
    "            if check in c:\n",
    "                df2[c] = np.log(df2[c]+1)\n",
    "                break\n",
    "        except Exception:\n",
    "            print_trace('log1p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:53.415634Z",
     "iopub.status.busy": "2022-01-23T02:34:53.414883Z",
     "iopub.status.idle": "2022-01-23T02:34:54.757020Z",
     "shell.execute_reply": "2022-01-23T02:34:54.756480Z",
     "shell.execute_reply.started": "2022-01-15T04:54:06.724354Z"
    },
    "papermill": {
     "duration": 1.384579,
     "end_time": "2022-01-23T02:34:54.757155",
     "exception": false,
     "start_time": "2022-01-23T02:34:53.372576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/2475865050.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'realized_volatility_roll{window_size}_by_book.total_volume.mean'] = \\\n",
      "/tmp/ipykernel_3888766/2475865050.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'realized_volatility_roll{window_size}_by_book.total_volume.mean'] = \\\n"
     ]
    }
   ],
   "source": [
    "# Rolling average of RV for similar trading volume\n",
    "try:\n",
    "    df2.sort_values(by=['stock_id', 'book.total_volume.sum'], inplace=True)\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    roll_target = 'book.log_return1.realized_volatility'\n",
    "\n",
    "    for window_size in [3, 10]:\n",
    "        df2[f'realized_volatility_roll{window_size}_by_book.total_volume.mean'] = \\\n",
    "            df2.groupby('stock_id')[roll_target].rolling(window_size, center=True, min_periods=1) \\\n",
    "                                                .mean() \\\n",
    "                                                .reset_index() \\\n",
    "                                                .sort_values(by=['level_1'])[roll_target].values\n",
    "except Exception:\n",
    "    print_trace('mean RV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:54.865738Z",
     "iopub.status.busy": "2022-01-23T02:34:54.859008Z",
     "iopub.status.idle": "2022-01-23T02:34:57.630440Z",
     "shell.execute_reply": "2022-01-23T02:34:57.631709Z",
     "shell.execute_reply.started": "2022-01-15T04:54:08.318718Z"
    },
    "papermill": {
     "duration": 2.836215,
     "end_time": "2022-01-23T02:34:57.631962",
     "exception": false,
     "start_time": "2022-01-23T02:34:54.795747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3888766/342520599.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'stock_id_emb{i}'] = df2['stock_id'].map(stock_id_emb[i])\n",
      "/tmp/ipykernel_3888766/342520599.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'stock_id_emb{i}'] = df2['stock_id'].map(stock_id_emb[i])\n",
      "/tmp/ipykernel_3888766/342520599.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df2[f'stock_id_emb{i}'] = df2['stock_id'].map(stock_id_emb[i])\n"
     ]
    }
   ],
   "source": [
    "# stock-id embedding (helps little)\n",
    "try:\n",
    "    lda_n = 3\n",
    "    lda = LatentDirichletAllocation(n_components=lda_n, random_state=0)\n",
    "\n",
    "    stock_id_emb = pd.DataFrame(\n",
    "        lda.fit_transform(pivot.transpose()), \n",
    "        index=df_pv.pivot('time_id', 'stock_id', 'vol').columns\n",
    "    )\n",
    "\n",
    "    for i in range(lda_n):\n",
    "        df2[f'stock_id_emb{i}'] = df2['stock_id'].map(stock_id_emb[i])\n",
    "except Exception:\n",
    "    print_trace('LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:57.804033Z",
     "iopub.status.busy": "2022-01-23T02:34:57.802818Z",
     "iopub.status.idle": "2022-01-23T02:34:59.440689Z",
     "shell.execute_reply": "2022-01-23T02:34:59.441129Z",
     "shell.execute_reply.started": "2022-01-15T04:54:13.038956Z"
    },
    "papermill": {
     "duration": 1.736319,
     "end_time": "2022-01-23T02:34:59.441286",
     "exception": false,
     "start_time": "2022-01-23T02:34:57.704967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df2[~df2.target.isnull()].copy()\n",
    "df_test = df2[df2.target.isnull()].copy()\n",
    "del df2, df_pv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037142,
     "end_time": "2022-01-23T02:34:59.516263",
     "exception": false,
     "start_time": "2022-01-23T02:34:59.479121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reverse Engineering time-id Order & Make CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:59.616772Z",
     "iopub.status.busy": "2022-01-23T02:34:59.615063Z",
     "iopub.status.idle": "2022-01-23T02:34:59.617414Z",
     "shell.execute_reply": "2022-01-23T02:34:59.617868Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.7715Z"
    },
    "papermill": {
     "duration": 0.063706,
     "end_time": "2022-01-23T02:34:59.618003",
     "exception": false,
     "start_time": "2022-01-23T02:34:59.554297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    e = time.time() - s\n",
    "    print(f\"[{name}] {e:.3f}sec\")\n",
    "    \n",
    "\n",
    "def calc_price2(df):\n",
    "    tick = sorted(np.diff(sorted(np.unique(df.values.flatten()))))[0]\n",
    "    return 0.01 / tick\n",
    "\n",
    "\n",
    "def calc_prices(r):\n",
    "    df = pd.read_parquet(r.book_path, columns=['time_id', 'ask_price1', 'ask_price2', 'bid_price1', 'bid_price2'])\n",
    "    df = df.set_index('time_id')\n",
    "    df = df.groupby(level='time_id').apply(calc_price2).to_frame('price').reset_index()\n",
    "    df['stock_id'] = r.stock_id\n",
    "    return df\n",
    "\n",
    "\n",
    "def sort_manifold(df, clf):\n",
    "    df_ = df.set_index('time_id')\n",
    "    df_ = pd.DataFrame(minmax_scale(df_.fillna(df_.mean())))\n",
    "\n",
    "    X_compoents = clf.fit_transform(df_)\n",
    "\n",
    "    dft = df.reindex(np.argsort(X_compoents[:,0])).reset_index(drop=True)\n",
    "    return np.argsort(X_compoents[:, 0]), X_compoents\n",
    "\n",
    "\n",
    "def reconstruct_time_id_order():\n",
    "    with timer('load files'):\n",
    "        df_files = pd.DataFrame(\n",
    "            {'book_path': glob.glob(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction/book_train.parquet/**/*.parquet'))}) \\\n",
    "            .eval('stock_id = book_path.str.extract(\"stock_id=(\\d+)\").astype(\"int\")', engine='python')\n",
    "\n",
    "    with timer('calc prices'):\n",
    "        df_prices = pd.concat(Parallel(n_jobs=4, verbose=51)(delayed(calc_prices)(r) for _, r in df_files.iterrows()))\n",
    "        df_prices = df_prices.pivot('time_id', 'stock_id', 'price')\n",
    "        df_prices.columns = [f'stock_id={i}' for i in df_prices.columns]\n",
    "        df_prices = df_prices.reset_index(drop=False)\n",
    "\n",
    "    with timer('t-SNE(400) -> 50'):\n",
    "        clf = TSNE(n_components=1, perplexity=400, random_state=0, n_iter=2000)\n",
    "        order, X_compoents = sort_manifold(df_prices, clf)\n",
    "\n",
    "        clf = TSNE(n_components=1, perplexity=50, random_state=0, init=X_compoents, n_iter=2000, method='exact')\n",
    "        order, X_compoents = sort_manifold(df_prices, clf)\n",
    "\n",
    "        df_ordered = df_prices.reindex(order).reset_index(drop=True)\n",
    "        if df_ordered['stock_id=61'].iloc[0] > df_ordered['stock_id=61'].iloc[-1]:\n",
    "            df_ordered = df_ordered.reindex(df_ordered.index[::-1]).reset_index(drop=True)\n",
    "\n",
    "    # AMZN\n",
    "    plt.plot(df_ordered['stock_id=61'])\n",
    "    \n",
    "    return df_ordered[['time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:34:59.705424Z",
     "iopub.status.busy": "2022-01-23T02:34:59.704651Z",
     "iopub.status.idle": "2022-01-23T02:35:01.635920Z",
     "shell.execute_reply": "2022-01-23T02:35:01.636972Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.801275Z"
    },
    "papermill": {
     "duration": 1.981013,
     "end_time": "2022-01-23T02:35:01.637181",
     "exception": false,
     "start_time": "2022-01-23T02:34:59.656168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CV_SPLIT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mCV_SPLIT\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m timer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalculate order of time-id\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m USE_PRECOMPUTE_FEATURES:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CV_SPLIT' is not defined"
     ]
    }
   ],
   "source": [
    "if CV_SPLIT == 'time':\n",
    "    with timer('calculate order of time-id'):\n",
    "        if USE_PRECOMPUTE_FEATURES:\n",
    "            timeid_order = pd.read_csv(os.path.join(DATA_DIR, 'optiver-time-id-ordered', 'time_id_order.csv'))\n",
    "        else:\n",
    "            timeid_order = reconstruct_time_id_order()\n",
    "\n",
    "    with timer('make folds'):\n",
    "        timeid_order['time_id_order'] = np.arange(len(timeid_order))\n",
    "        df_train['time_id_order'] = df_train['time_id'].map(timeid_order.set_index('time_id')['time_id_order'])\n",
    "        df_train = df_train.sort_values(['time_id_order', 'stock_id']).reset_index(drop=True)\n",
    "\n",
    "        folds_border = [3830 - 383*4, 3830 - 383*3, 3830 - 383*2, 3830 - 383*1]\n",
    "        time_id_orders = df_train['time_id_order']\n",
    "\n",
    "        folds = []\n",
    "        for i, border in enumerate(folds_border):\n",
    "            idx_train = np.where(time_id_orders < border)[0]\n",
    "            idx_valid = np.where((border <= time_id_orders) & (time_id_orders < border + 383))[0]\n",
    "            folds.append((idx_train, idx_valid))\n",
    "\n",
    "            print(f\"folds{i}: train={len(idx_train)}, valid={len(idx_valid)}\")\n",
    "\n",
    "    del df_train['time_id_order']\n",
    "elif CV_SPLIT == 'group':\n",
    "    gkf = GroupKFold(n_splits=4)\n",
    "    folds = []\n",
    "\n",
    "    for i, (idx_train, idx_valid) in enumerate(gkf.split(df_train, None, groups=df_train['time_id'])):\n",
    "        folds.append((idx_train, idx_valid))\n",
    "else:\n",
    "    raise ValueError()\n",
    "print(timeid_order)\n",
    "# df_train.reset_index(drop=True, inplace=True)\n",
    "# df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.067715,
     "end_time": "2022-01-23T02:35:01.777174",
     "exception": false,
     "start_time": "2022-01-23T02:35:01.709459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LightGBM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:35:01.921148Z",
     "iopub.status.busy": "2022-01-23T02:35:01.920367Z",
     "iopub.status.idle": "2022-01-23T02:35:01.933964Z",
     "shell.execute_reply": "2022-01-23T02:35:01.934928Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.902446Z"
    },
    "papermill": {
     "duration": 0.091675,
     "end_time": "2022-01-23T02:35:01.935102",
     "exception": false,
     "start_time": "2022-01-23T02:35:01.843427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "\n",
    "def feval_RMSPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False\n",
    "\n",
    "\n",
    "# from: https://blog.amedama.jp/entry/lightgbm-cv-feature-importance\n",
    "def plot_importance(cvbooster, figsize=(10, 10)):\n",
    "    raw_importances = cvbooster.feature_importance(importance_type='gain')\n",
    "    feature_name = cvbooster.boosters[0].feature_name()\n",
    "    importance_df = pd.DataFrame(data=raw_importances,\n",
    "                                 columns=feature_name)\n",
    "    # order by average importance across folds\n",
    "    sorted_indices = importance_df.mean(axis=0).sort_values(ascending=False).index\n",
    "    sorted_importance_df = importance_df.loc[:, sorted_indices]\n",
    "    # plot top-n\n",
    "    PLOT_TOP_N = 50\n",
    "    plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n",
    "    _, ax = plt.subplots(figsize=figsize)\n",
    "    ax.grid()\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel('Feature')\n",
    "    ax.set_xlabel('Importance')\n",
    "    sns.boxplot(data=sorted_importance_df[plot_cols],\n",
    "                orient='h',\n",
    "                ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_X(df_src):\n",
    "    cols = [c for c in df_src.columns if c not in ['time_id', 'target', 'tick_size']]\n",
    "    return df_src[cols]\n",
    "\n",
    "\n",
    "class EnsembleModel:\n",
    "    def __init__(self, models: List[lgb.Booster], weights: Optional[List[float]] = None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "        features = list(self.models[0].feature_name())\n",
    "\n",
    "        for m in self.models[1:]:\n",
    "            assert features == list(m.feature_name())\n",
    "\n",
    "    def predict(self, x):\n",
    "        predicted = np.zeros((len(x), len(self.models)))\n",
    "\n",
    "        for i, m in enumerate(self.models):\n",
    "            w = self.weights[i] if self.weights is not None else 1\n",
    "            predicted[:, i] = w * m.predict(x)\n",
    "\n",
    "        ttl = np.sum(self.weights) if self.weights is not None else len(self.models)\n",
    "        return np.sum(predicted, axis=1) / ttl\n",
    "\n",
    "    def feature_name(self) -> List[str]:\n",
    "        return self.models[0].feature_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T02:35:02.048565Z",
     "iopub.status.busy": "2022-01-23T02:35:02.044618Z",
     "iopub.status.idle": "2022-01-23T03:35:55.320275Z",
     "shell.execute_reply": "2022-01-23T03:35:55.319782Z",
     "shell.execute_reply.started": "2022-01-15T04:54:14.922483Z"
    },
    "papermill": {
     "duration": 3653.32245,
     "end_time": "2022-01-23T03:35:55.320410",
     "exception": false,
     "start_time": "2022-01-23T02:35:01.997960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428932, 584)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steven/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:577: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.335904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.348022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.351803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.439827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steven/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py:620: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's l2: 7.38841e-07 + 1.60798e-07\tcv_agg's RMSPE: 0.38014 + 0.00986678\n",
      "[40]\tcv_agg's l2: 4.52997e-07 + 8.39884e-08\tcv_agg's RMSPE: 0.298575 + 0.00421469\n",
      "[60]\tcv_agg's l2: 3.23867e-07 + 5.08634e-08\tcv_agg's RMSPE: 0.253165 + 0.00590573\n",
      "[80]\tcv_agg's l2: 2.64498e-07 + 3.70575e-08\tcv_agg's RMSPE: 0.229228 + 0.00877693\n",
      "[100]\tcv_agg's l2: 2.36538e-07 + 3.15655e-08\tcv_agg's RMSPE: 0.217003 + 0.0104855\n",
      "[120]\tcv_agg's l2: 2.22859e-07 + 2.93145e-08\tcv_agg's RMSPE: 0.21073 + 0.0113045\n",
      "[140]\tcv_agg's l2: 2.15812e-07 + 2.83972e-08\tcv_agg's RMSPE: 0.207413 + 0.0116591\n",
      "[160]\tcv_agg's l2: 2.11899e-07 + 2.79571e-08\tcv_agg's RMSPE: 0.205535 + 0.0117838\n",
      "[180]\tcv_agg's l2: 2.09614e-07 + 2.7764e-08\tcv_agg's RMSPE: 0.204428 + 0.0118019\n",
      "[200]\tcv_agg's l2: 2.08055e-07 + 2.76584e-08\tcv_agg's RMSPE: 0.203657 + 0.0117621\n",
      "[220]\tcv_agg's l2: 2.06944e-07 + 2.75676e-08\tcv_agg's RMSPE: 0.20311 + 0.0117137\n",
      "[240]\tcv_agg's l2: 2.06171e-07 + 2.75507e-08\tcv_agg's RMSPE: 0.202722 + 0.011675\n",
      "[260]\tcv_agg's l2: 2.0558e-07 + 2.75154e-08\tcv_agg's RMSPE: 0.20243 + 0.0116247\n",
      "[280]\tcv_agg's l2: 2.05143e-07 + 2.74899e-08\tcv_agg's RMSPE: 0.202208 + 0.0115926\n",
      "[300]\tcv_agg's l2: 2.04802e-07 + 2.74674e-08\tcv_agg's RMSPE: 0.202035 + 0.0115549\n",
      "[320]\tcv_agg's l2: 2.0448e-07 + 2.74382e-08\tcv_agg's RMSPE: 0.201877 + 0.0115266\n",
      "[340]\tcv_agg's l2: 2.04243e-07 + 2.73808e-08\tcv_agg's RMSPE: 0.20176 + 0.0115008\n",
      "[360]\tcv_agg's l2: 2.04005e-07 + 2.73557e-08\tcv_agg's RMSPE: 0.201643 + 0.0114788\n",
      "[380]\tcv_agg's l2: 2.03876e-07 + 2.73625e-08\tcv_agg's RMSPE: 0.201578 + 0.0114638\n",
      "[400]\tcv_agg's l2: 2.03734e-07 + 2.74056e-08\tcv_agg's RMSPE: 0.201497 + 0.0114427\n",
      "[420]\tcv_agg's l2: 2.03588e-07 + 2.73781e-08\tcv_agg's RMSPE: 0.20143 + 0.0114388\n",
      "[440]\tcv_agg's l2: 2.03483e-07 + 2.73462e-08\tcv_agg's RMSPE: 0.20138 + 0.0114341\n",
      "[460]\tcv_agg's l2: 2.03392e-07 + 2.73468e-08\tcv_agg's RMSPE: 0.20133 + 0.0114278\n",
      "[480]\tcv_agg's l2: 2.03282e-07 + 2.73439e-08\tcv_agg's RMSPE: 0.201277 + 0.0114202\n",
      "[500]\tcv_agg's l2: 2.03214e-07 + 2.73473e-08\tcv_agg's RMSPE: 0.201238 + 0.0114135\n",
      "[520]\tcv_agg's l2: 2.0312e-07 + 2.73241e-08\tcv_agg's RMSPE: 0.201198 + 0.0114025\n",
      "[540]\tcv_agg's l2: 2.03073e-07 + 2.7369e-08\tcv_agg's RMSPE: 0.20117 + 0.0114015\n",
      "[560]\tcv_agg's l2: 2.03015e-07 + 2.7383e-08\tcv_agg's RMSPE: 0.20114 + 0.0113943\n",
      "[580]\tcv_agg's l2: 2.02989e-07 + 2.74102e-08\tcv_agg's RMSPE: 0.20112 + 0.0113868\n",
      "[600]\tcv_agg's l2: 2.02956e-07 + 2.74412e-08\tcv_agg's RMSPE: 0.201105 + 0.011394\n",
      "[620]\tcv_agg's l2: 2.02898e-07 + 2.74569e-08\tcv_agg's RMSPE: 0.201073 + 0.0113911\n",
      "[640]\tcv_agg's l2: 2.02876e-07 + 2.74731e-08\tcv_agg's RMSPE: 0.201063 + 0.0113898\n",
      "[660]\tcv_agg's l2: 2.02825e-07 + 2.74344e-08\tcv_agg's RMSPE: 0.201038 + 0.011383\n",
      "[680]\tcv_agg's l2: 2.02825e-07 + 2.75048e-08\tcv_agg's RMSPE: 0.201035 + 0.0113894\n",
      "[700]\tcv_agg's l2: 2.02797e-07 + 2.75084e-08\tcv_agg's RMSPE: 0.20102 + 0.0113918\n",
      "[720]\tcv_agg's l2: 2.0279e-07 + 2.75487e-08\tcv_agg's RMSPE: 0.201015 + 0.0113868\n",
      "[740]\tcv_agg's l2: 2.02779e-07 + 2.75504e-08\tcv_agg's RMSPE: 0.201008 + 0.0113829\n",
      "[760]\tcv_agg's l2: 2.02783e-07 + 2.75459e-08\tcv_agg's RMSPE: 0.201008 + 0.0113829\n",
      "[780]\tcv_agg's l2: 2.02777e-07 + 2.75685e-08\tcv_agg's RMSPE: 0.201008 + 0.0113873\n",
      "[800]\tcv_agg's l2: 2.02773e-07 + 2.75774e-08\tcv_agg's RMSPE: 0.201005 + 0.0113916\n",
      "[820]\tcv_agg's l2: 2.02779e-07 + 2.75857e-08\tcv_agg's RMSPE: 0.201005 + 0.0113912\n",
      "[840]\tcv_agg's l2: 2.02754e-07 + 2.75658e-08\tcv_agg's RMSPE: 0.200995 + 0.0113806\n",
      "[860]\tcv_agg's l2: 2.02755e-07 + 2.75682e-08\tcv_agg's RMSPE: 0.200995 + 0.0113801\n",
      "[880]\tcv_agg's l2: 2.02754e-07 + 2.75865e-08\tcv_agg's RMSPE: 0.200992 + 0.0113836\n",
      "[900]\tcv_agg's l2: 2.02767e-07 + 2.76075e-08\tcv_agg's RMSPE: 0.201 + 0.0113928\n",
      "[920]\tcv_agg's l2: 2.02786e-07 + 2.76267e-08\tcv_agg's RMSPE: 0.201008 + 0.0113913\n",
      "[940]\tcv_agg's l2: 2.02792e-07 + 2.76198e-08\tcv_agg's RMSPE: 0.201013 + 0.0113942\n",
      "[960]\tcv_agg's l2: 2.02799e-07 + 2.76224e-08\tcv_agg's RMSPE: 0.201015 + 0.0113895\n",
      "[980]\tcv_agg's l2: 2.02813e-07 + 2.76269e-08\tcv_agg's RMSPE: 0.20102 + 0.0114038\n",
      "[1000]\tcv_agg's l2: 2.02823e-07 + 2.76527e-08\tcv_agg's RMSPE: 0.201027 + 0.0114121\n",
      "[1020]\tcv_agg's l2: 2.0285e-07 + 2.76869e-08\tcv_agg's RMSPE: 0.20104 + 0.0114181\n",
      "[1040]\tcv_agg's l2: 2.02868e-07 + 2.77257e-08\tcv_agg's RMSPE: 0.201042 + 0.0114178\n",
      "[1060]\tcv_agg's l2: 2.02892e-07 + 2.77317e-08\tcv_agg's RMSPE: 0.201058 + 0.011426\n",
      "# overall RMSPE: 0.2009875\n",
      "[lgb.cv] 401.134sec\n",
      "# fold0 RMSPE: 0.20555073006708058\n",
      "# fold1 RMSPE: 0.20945316927969115\n",
      "# fold2 RMSPE: 0.2075343824638873\n",
      "# fold3 RMSPE: 0.18142291886810902\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.813982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.810432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.805092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.813741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.843208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[retraining] 566.163sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35857"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = GBDT_LR\n",
    "if SHORTCUT_GBDT_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "    # to save GPU quota\n",
    "    lr = 0.3\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'verbose': 0,\n",
    "    'metric': '',\n",
    "    'reg_alpha': 5,\n",
    "    'reg_lambda': 5,\n",
    "    'min_data_in_leaf': 1000,\n",
    "    'max_depth': -1,\n",
    "    'num_leaves': 128,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'learning_rate': lr\n",
    "}\n",
    "\n",
    "X = get_X(df_train)\n",
    "y = df_train['target']\n",
    "X.to_feather('X.f')\n",
    "df_train[['target']].to_feather('y.f')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "if PREDICT_GBDT:\n",
    "    ds = lgb.Dataset(X, y, weight=1/np.power(y, 2))\n",
    "\n",
    "    with timer('lgb.cv'):\n",
    "        ret = lgb.cv(params, ds, num_boost_round=8000, folds=folds, #cv,\n",
    "                     feval=feval_RMSPE, stratified=False, \n",
    "                     return_cvbooster=True, verbose_eval=20,\n",
    "                     early_stopping_rounds=int(40*0.1/lr))\n",
    "\n",
    "        print(f\"# overall RMSPE: {ret['RMSPE-mean'][-1]}\")\n",
    "\n",
    "    best_iteration = len(ret['RMSPE-mean'])\n",
    "    for i in range(len(folds)):\n",
    "        y_pred = ret['cvbooster'].boosters[i].predict(X.iloc[folds[i][1]], num_iteration=best_iteration)\n",
    "        y_true = y.iloc[folds[i][1]]\n",
    "        print(f\"# fold{i} RMSPE: {rmspe(y_true, y_pred)}\")\n",
    "        \n",
    "        if i == len(folds) - 1:\n",
    "            np.save('pred_gbdt.npy', y_pred)\n",
    "\n",
    "    plot_importance(ret['cvbooster'], figsize=(10, 20))\n",
    "\n",
    "    boosters = []\n",
    "    with timer('retraining'):\n",
    "        for i in range(GBDT_NUM_MODELS):\n",
    "            params['seed'] = i\n",
    "            boosters.append(lgb.train(params, ds, num_boost_round=int(1.1*best_iteration)))\n",
    "\n",
    "    booster = EnsembleModel(boosters)\n",
    "    del ret\n",
    "    del ds\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057064,
     "end_time": "2022-01-23T03:35:55.434906",
     "exception": false,
     "start_time": "2022-01-23T03:35:55.377842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-23T03:35:55.569557Z",
     "iopub.status.busy": "2022-01-23T03:35:55.558558Z",
     "iopub.status.idle": "2022-01-23T03:35:56.706846Z",
     "shell.execute_reply": "2022-01-23T03:35:56.705908Z",
     "shell.execute_reply.started": "2022-01-15T04:57:16.2193Z"
    },
    "papermill": {
     "duration": 1.211778,
     "end_time": "2022-01-23T03:35:56.706992",
     "exception": false,
     "start_time": "2022-01-23T03:35:55.495214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.decomposition import PCA\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "\n",
    "null_check_cols = [\n",
    "    'book.log_return1.realized_volatility',\n",
    "    'book_150.log_return1.realized_volatility',\n",
    "    'book_300.log_return1.realized_volatility',\n",
    "    'book_450.log_return1.realized_volatility',\n",
    "    'trade.log_return.realized_volatility',\n",
    "    'trade_150.log_return.realized_volatility',\n",
    "    'trade_300.log_return.realized_volatility',\n",
    "    'trade_450.log_return.realized_volatility'\n",
    "]\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def rmspe_metric(y_true, y_pred):\n",
    "    rmspe = np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_loss(y_true, y_pred):\n",
    "    rmspe = torch.sqrt(torch.mean(torch.square((y_true - y_pred) / y_true)))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "class RMSPE(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"rmspe\"\n",
    "        self._maximize = False\n",
    "\n",
    "    def __call__(self, y_true, y_score):\n",
    "        return np.sqrt(np.mean(np.square((y_true - y_score) / y_true)))\n",
    "\n",
    "def RMSPELoss_Tabnet(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 )).clone()\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, x_num: np.ndarray, x_cat: np.ndarray, y: Optional[np.ndarray]):\n",
    "        super().__init__()\n",
    "        self.x_num = x_num\n",
    "        self.x_cat = x_cat\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_num)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x_num[idx], torch.LongTensor(self.x_cat[idx])\n",
    "        else:\n",
    "            return self.x_num[idx], torch.LongTensor(self.x_cat[idx]), self.y[idx]\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 src_num_dim: int,\n",
    "                 n_categories: List[int],\n",
    "                 dropout: float = 0.0,\n",
    "                 hidden: int = 50,\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0.2,\n",
    "                 bn: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embs = nn.ModuleList([\n",
    "            nn.Embedding(x, emb_dim) for x in n_categories])\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.dropout_cat = nn.Dropout(dropout_cat)\n",
    "\n",
    "        if bn:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim + self.cat_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "        else:\n",
    "            self.sequence = nn.Sequential(\n",
    "                nn.Linear(src_num_dim + self.cat_dim, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embs = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embs)]\n",
    "        x_cat_emb = self.dropout_cat(torch.cat(embs, 1))\n",
    "        x_all = torch.cat([x_num, x_cat_emb], 1)\n",
    "        x = self.sequence(x_all)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_features: int,\n",
    "                 hidden_size: int,\n",
    "                 n_categories: List[int],\n",
    "                 emb_dim: int = 10,\n",
    "                 dropout_cat: float = 0.2,\n",
    "                 channel_1: int = 256,\n",
    "                 channel_2: int = 512,\n",
    "                 channel_3: int = 512,\n",
    "                 dropout_top: float = 0.1,\n",
    "                 dropout_mid: float = 0.3,\n",
    "                 dropout_bottom: float = 0.2,\n",
    "                 weight_norm: bool = True,\n",
    "                 two_stage: bool = True,\n",
    "                 celu: bool = True,\n",
    "                 kernel1: int = 5,\n",
    "                 leaky_relu: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        num_targets = 1\n",
    "\n",
    "        cha_1_reshape = int(hidden_size / channel_1)\n",
    "        cha_po_1 = int(hidden_size / channel_1 / 2)\n",
    "        cha_po_2 = int(hidden_size / channel_1 / 2 / 2) * channel_3\n",
    "\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.cha_1 = channel_1\n",
    "        self.cha_2 = channel_2\n",
    "        self.cha_3 = channel_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "        self.two_stage = two_stage\n",
    "\n",
    "        self.expand = nn.Sequential(\n",
    "            nn.BatchNorm1d(num_features + self.cat_dim),\n",
    "            nn.Dropout(dropout_top),\n",
    "            nn.utils.weight_norm(nn.Linear(num_features + self.cat_dim, hidden_size), dim=None),\n",
    "            nn.CELU(0.06) if celu else nn.ReLU()\n",
    "        )\n",
    "\n",
    "        def _norm(layer, dim=None):\n",
    "            return nn.utils.weight_norm(layer, dim=dim) if weight_norm else layer\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(channel_1),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_1, channel_2, kernel_size=kernel1, stride=1, padding=kernel1 // 2, bias=False)),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(output_size=cha_po_1),\n",
    "            nn.BatchNorm1d(channel_2),\n",
    "            nn.Dropout(dropout_top),\n",
    "            _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if self.two_stage:\n",
    "            self.conv2 = nn.Sequential(\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_mid),\n",
    "                _norm(nn.Conv1d(channel_2, channel_2, kernel_size=3, stride=1, padding=1, bias=True)),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(channel_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Conv1d(channel_2, channel_3, kernel_size=5, stride=1, padding=2, bias=True)),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        if leaky_relu:\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.BatchNorm1d(cha_po_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Linear(cha_po_2, num_targets), dim=0),\n",
    "                nn.LeakyReLU()\n",
    "            )\n",
    "        else:\n",
    "            self.dense = nn.Sequential(\n",
    "                nn.BatchNorm1d(cha_po_2),\n",
    "                nn.Dropout(dropout_bottom),\n",
    "                _norm(nn.Linear(cha_po_2, num_targets), dim=0)\n",
    "            )\n",
    "\n",
    "        self.embs = nn.ModuleList([nn.Embedding(x, emb_dim) for x in n_categories])\n",
    "        self.cat_dim = emb_dim * len(n_categories)\n",
    "        self.dropout_cat = nn.Dropout(dropout_cat)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        embs = [embedding(x_cat[:, i]) for i, embedding in enumerate(self.embs)]\n",
    "        x_cat_emb = self.dropout_cat(torch.cat(embs, 1))\n",
    "        x = torch.cat([x_num, x_cat_emb], 1)\n",
    "\n",
    "        x = self.expand(x)\n",
    "\n",
    "        x = x.reshape(x.shape[0], self.cha_1, self.cha_1_reshape)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        if self.two_stage:\n",
    "            x = self.conv2(x) * x\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "        x = self.flt(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "\n",
    "def preprocess_nn(\n",
    "        X: pd.DataFrame,\n",
    "        scaler: Optional[StandardScaler] = None,\n",
    "        scaler_type: str = 'standard',\n",
    "        n_pca: int = -1,\n",
    "        na_cols: bool = True):\n",
    "    if na_cols:\n",
    "        #for c in X.columns:\n",
    "        for c in null_check_cols:\n",
    "            if c in X.columns:\n",
    "                X[f\"{c}_isnull\"] = X[c].isnull().astype(int)\n",
    "\n",
    "    cat_cols = [c for c in X.columns if c in ['time_id', 'stock_id']]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    X_num = X[num_cols].values.astype(np.float32)\n",
    "    X_cat = np.nan_to_num(X[cat_cols].values.astype(np.int32))\n",
    "\n",
    "    def _pca(X_num_):\n",
    "        if n_pca > 0:\n",
    "            pca = PCA(n_components=n_pca, random_state=0)\n",
    "            return pca.fit_transform(X_num)\n",
    "        return X_num\n",
    "\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_num = scaler.fit_transform(X_num)\n",
    "        X_num = np.nan_to_num(X_num, posinf=0, neginf=0)\n",
    "        return _pca(X_num), X_cat, cat_cols, scaler\n",
    "    else:\n",
    "        X_num = scaler.transform(X_num) #TODO: infでも大丈夫？\n",
    "        X_num = np.nan_to_num(X_num, posinf=0, neginf=0)\n",
    "        return _pca(X_num), X_cat, cat_cols\n",
    "\n",
    "\n",
    "def train_epoch(data_loader: DataLoader,\n",
    "                model: nn.Module,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                device,\n",
    "                clip_grad: float = 1.5):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    step = 0\n",
    "\n",
    "    for x_num, x_cat, y in tqdm(data_loader, position=0, leave=True, desc='Training'):\n",
    "        batch_size = x_num.size(0)\n",
    "        x_num = x_num.to(device, dtype=torch.float)\n",
    "        x_cat = x_cat.to(device)\n",
    "        y = y.to(device, dtype=torch.float)\n",
    "\n",
    "        loss = rmspe_loss(y, model(x_num, x_cat))\n",
    "        losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def evaluate(data_loader: DataLoader, model, device):\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    final_targets = []\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_num, x_cat, y in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            batch_size = x_num.size(0)\n",
    "            x_num = x_num.to(device, dtype=torch.float)\n",
    "            x_cat = x_cat.to(device)\n",
    "            y = y.to(device, dtype=torch.float)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(x_num, x_cat)\n",
    "\n",
    "            loss = rmspe_loss(y, output)\n",
    "            # record loss\n",
    "            losses.update(loss.detach().cpu().numpy(), batch_size)\n",
    "\n",
    "            targets = y.detach().cpu().numpy()\n",
    "            output = output.detach().cpu().numpy()\n",
    "\n",
    "            final_targets.append(targets)\n",
    "            final_outputs.append(output)\n",
    "\n",
    "    final_targets = np.concatenate(final_targets)\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "\n",
    "    try:\n",
    "        metric = rmspe_metric(final_targets, final_outputs)\n",
    "    except:\n",
    "        metric = None\n",
    "\n",
    "    return final_outputs, final_targets, losses.avg, metric\n",
    "\n",
    "\n",
    "def predict_nn(X: pd.DataFrame,\n",
    "               model: Union[List[MLP], MLP],\n",
    "               scaler: StandardScaler,\n",
    "               device,\n",
    "               ensemble_method='mean'):\n",
    "    if not isinstance(model, list):\n",
    "        model = [model]\n",
    "\n",
    "    for m in model:\n",
    "        m.eval()\n",
    "    X_num, X_cat, cat_cols = preprocess_nn(X.copy(), scaler=scaler)\n",
    "    valid_dataset = TabularDataset(X_num, X_cat, None)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                               batch_size=512,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=4)\n",
    "\n",
    "    final_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_num, x_cat in tqdm(valid_loader, position=0, leave=True, desc='Evaluating'):\n",
    "            x_num = x_num.to(device, dtype=torch.float)\n",
    "            x_cat = x_cat.to(device)\n",
    "\n",
    "            outputs = []\n",
    "            with torch.no_grad():\n",
    "                for m in model:\n",
    "                    output = m(x_num, x_cat)\n",
    "                    outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "            if ensemble_method == 'median':\n",
    "                pred = np.nanmedian(np.array(outputs), axis=0)\n",
    "            else:\n",
    "                pred = np.array(outputs).mean(axis=0)\n",
    "            final_outputs.append(pred)\n",
    "\n",
    "    final_outputs = np.concatenate(final_outputs)\n",
    "    return final_outputs\n",
    "\n",
    "\n",
    "def predict_tabnet(X: pd.DataFrame,\n",
    "                   model: Union[List[TabNetRegressor], TabNetRegressor],\n",
    "                   scaler: StandardScaler,\n",
    "                   ensemble_method='mean'):\n",
    "    if not isinstance(model, list):\n",
    "        model = [model]\n",
    "\n",
    "    X_num, X_cat, cat_cols = preprocess_nn(X.copy(), scaler=scaler)\n",
    "    X_processed = np.concatenate([X_cat, X_num], axis=1)\n",
    "\n",
    "    predicted = []\n",
    "    for m in model:\n",
    "        predicted.append(m.predict(X_processed))\n",
    "\n",
    "    if ensemble_method == 'median':\n",
    "        pred = np.nanmedian(np.array(predicted), axis=0)\n",
    "    else:\n",
    "        pred = np.array(predicted).mean(axis=0)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def train_tabnet(X: pd.DataFrame,\n",
    "                 y: pd.DataFrame,\n",
    "                 folds: List[Tuple],\n",
    "                 batch_size: int = 1024,\n",
    "                 lr: float = 1e-3,\n",
    "                 model_path: str = 'fold_{}.pth',\n",
    "                 scaler_type: str = 'standard',\n",
    "                 output_dir: str = 'artifacts',\n",
    "                 epochs: int = 250,\n",
    "                 seed: int = 42,\n",
    "                 n_pca: int = -1,\n",
    "                 na_cols: bool = True,\n",
    "                 patience: int = 10,\n",
    "                 factor: float = 0.5,\n",
    "                 gamma: float = 2.0,\n",
    "                 lambda_sparse: float = 8.0,\n",
    "                 n_steps: int = 2,\n",
    "                 scheduler_type: str = 'cosine',\n",
    "                 n_a: int = 16):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    y = y.values.astype(np.float32)\n",
    "    X_num, X_cat, cat_cols, scaler = preprocess_nn(X.copy(), scaler_type=scaler_type, n_pca=n_pca, na_cols=na_cols)\n",
    "\n",
    "    best_losses = []\n",
    "    best_predictions = []\n",
    "\n",
    "    for cv_idx, (train_idx, valid_idx) in enumerate(folds):\n",
    "        X_tr, X_va = X_num[train_idx], X_num[valid_idx]\n",
    "        X_tr_cat, X_va_cat = X_cat[train_idx], X_cat[valid_idx]\n",
    "        y_tr, y_va = y[train_idx], y[valid_idx]\n",
    "        y_tr = y_tr.reshape(-1,1)\n",
    "        y_va = y_va.reshape(-1,1)\n",
    "        X_tr = np.concatenate([X_tr_cat, X_tr], axis=1)\n",
    "        X_va = np.concatenate([X_va_cat, X_va], axis=1)\n",
    "\n",
    "        cat_idxs = [0]\n",
    "        cat_dims = [128]\n",
    "\n",
    "        if scheduler_type == 'cosine':\n",
    "            scheduler_params = dict(T_0=200, T_mult=1, eta_min=1e-4, last_epoch=-1, verbose=False)\n",
    "            scheduler_fn = CosineAnnealingWarmRestarts\n",
    "        else:\n",
    "            scheduler_params = {'mode': 'min', 'min_lr': 1e-7, 'patience': patience, 'factor': factor, 'verbose': True}\n",
    "            scheduler_fn = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "\n",
    "        model = TabNetRegressor(\n",
    "            cat_idxs=cat_idxs,\n",
    "            cat_dims=cat_dims,\n",
    "            cat_emb_dim=1,\n",
    "            n_d=n_a,\n",
    "            n_a=n_a,\n",
    "            n_steps=n_steps,\n",
    "            gamma=gamma,\n",
    "            n_independent=2,\n",
    "            n_shared=2,\n",
    "            lambda_sparse=lambda_sparse,\n",
    "            optimizer_fn=torch.optim.Adam,\n",
    "            optimizer_params={'lr': lr},\n",
    "            mask_type=\"entmax\",\n",
    "            scheduler_fn=scheduler_fn,\n",
    "            scheduler_params=scheduler_params,\n",
    "            seed=seed,\n",
    "            verbose=10\n",
    "            #device_name=device,\n",
    "            #clip_value=1.5\n",
    "        )\n",
    "\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], max_epochs=epochs, patience=50, batch_size=1024*20,\n",
    "                  virtual_batch_size=batch_size, num_workers=4, drop_last=False, eval_metric=[RMSPE], loss_fn=RMSPELoss_Tabnet)\n",
    "\n",
    "        path = os.path.join(output_dir, model_path.format(cv_idx))\n",
    "        model.save_model(path)\n",
    "\n",
    "        predicted = model.predict(X_va)\n",
    "\n",
    "        rmspe = rmspe_metric(y_va, predicted)\n",
    "        best_losses.append(rmspe)\n",
    "        best_predictions.append(predicted)\n",
    "\n",
    "    return best_losses, best_predictions, scaler, model\n",
    "\n",
    "\n",
    "def train_nn(X: pd.DataFrame,\n",
    "             y: pd.DataFrame,\n",
    "             folds: List[Tuple],\n",
    "             device,\n",
    "             emb_dim: int = 25,\n",
    "             batch_size: int = 1024,\n",
    "             model_type: str = 'mlp',\n",
    "             mlp_dropout: float = 0.0,\n",
    "             mlp_hidden: int = 64,\n",
    "             mlp_bn: bool = False,\n",
    "             cnn_hidden: int = 64,\n",
    "             cnn_channel1: int = 32,\n",
    "             cnn_channel2: int = 32,\n",
    "             cnn_channel3: int = 32,\n",
    "             cnn_kernel1: int = 5,\n",
    "             cnn_celu: bool = False,\n",
    "             cnn_weight_norm: bool = False,\n",
    "             dropout_emb: bool = 0.0,\n",
    "             lr: float = 1e-3,\n",
    "             weight_decay: float = 0.0,\n",
    "             model_path: str = 'fold_{}.pth',\n",
    "             scaler_type: str = 'standard',\n",
    "             output_dir: str = 'artifacts',\n",
    "             scheduler_type: str = 'onecycle',\n",
    "             optimizer_type: str = 'adam',\n",
    "             max_lr: float = 0.01,\n",
    "             epochs: int = 30,\n",
    "             seed: int = 42,\n",
    "             n_pca: int = -1,\n",
    "             batch_double_freq: int = 50,\n",
    "             cnn_dropout: float = 0.1,\n",
    "             na_cols: bool = True,\n",
    "             cnn_leaky_relu: bool = False,\n",
    "             patience: int = 8,\n",
    "             factor: float = 0.5):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    y = y.values.astype(np.float32)\n",
    "    X_num, X_cat, cat_cols, scaler = preprocess_nn(X.copy(), scaler_type=scaler_type, n_pca=n_pca, na_cols=na_cols)\n",
    "\n",
    "    best_losses = []\n",
    "    best_predictions = []\n",
    "\n",
    "    for cv_idx, (train_idx, valid_idx) in enumerate(folds):\n",
    "        X_tr, X_va = X_num[train_idx], X_num[valid_idx]\n",
    "        X_tr_cat, X_va_cat = X_cat[train_idx], X_cat[valid_idx]\n",
    "        y_tr, y_va = y[train_idx], y[valid_idx]\n",
    "\n",
    "        cur_batch = batch_size\n",
    "        best_loss = 1e10\n",
    "        best_prediction = None\n",
    "\n",
    "        print(f\"fold {cv_idx} train: {X_tr.shape}, valid: {X_va.shape}\")\n",
    "\n",
    "        train_dataset = TabularDataset(X_tr, X_tr_cat, y_tr)\n",
    "        valid_dataset = TabularDataset(X_va, X_va_cat, y_va)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cur_batch, shuffle=True,\n",
    "                                                   num_workers=4)\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=cur_batch, shuffle=False,\n",
    "                                                   num_workers=4)\n",
    "\n",
    "        if model_type == 'mlp':\n",
    "            model = MLP(X_tr.shape[1],\n",
    "                        n_categories=[128],\n",
    "                        dropout=mlp_dropout, hidden=mlp_hidden, emb_dim=emb_dim,\n",
    "                        dropout_cat=dropout_emb, bn=mlp_bn)\n",
    "        elif model_type == 'cnn':\n",
    "            model = CNN(X_tr.shape[1],\n",
    "                        hidden_size=cnn_hidden,\n",
    "                        n_categories=[128],\n",
    "                        emb_dim=emb_dim,\n",
    "                        dropout_cat=dropout_emb,\n",
    "                        channel_1=cnn_channel1,\n",
    "                        channel_2=cnn_channel2,\n",
    "                        channel_3=cnn_channel3,\n",
    "                        two_stage=False,\n",
    "                        kernel1=cnn_kernel1,\n",
    "                        celu=cnn_celu,\n",
    "                        dropout_top=cnn_dropout,\n",
    "                        dropout_mid=cnn_dropout,\n",
    "                        dropout_bottom=cnn_dropout,\n",
    "                        weight_norm=cnn_weight_norm,\n",
    "                        leaky_relu=cnn_leaky_relu)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        model = model.to(device)\n",
    "\n",
    "        if optimizer_type == 'adamw':\n",
    "            opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'adam':\n",
    "            opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        scheduler = epoch_scheduler = None\n",
    "        if scheduler_type == 'onecycle':\n",
    "            scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=opt, pct_start=0.1, div_factor=1e3,\n",
    "                                                            max_lr=max_lr, epochs=epochs,\n",
    "                                                            steps_per_epoch=len(train_loader))\n",
    "        elif scheduler_type == 'reduce':\n",
    "            epoch_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=opt,\n",
    "                                                                         mode='min',\n",
    "                                                                         min_lr=1e-7,\n",
    "                                                                         patience=patience,\n",
    "                                                                         verbose=True,\n",
    "                                                                         factor=factor)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            if epoch > 0 and epoch % batch_double_freq == 0:\n",
    "                cur_batch = cur_batch * 2\n",
    "                print(f'batch: {cur_batch}')\n",
    "                train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                           batch_size=cur_batch,\n",
    "                                                           shuffle=True,\n",
    "                                                           num_workers=4)\n",
    "            train_loss = train_epoch(train_loader, model, opt, scheduler, device)\n",
    "            predictions, valid_targets, valid_loss, rmspe = evaluate(valid_loader, model, device=device)\n",
    "            print(f\"epoch {epoch}, train loss: {train_loss:.3f}, valid rmspe: {rmspe:.3f}\")\n",
    "\n",
    "            if epoch_scheduler is not None:\n",
    "                epoch_scheduler.step(rmspe)\n",
    "\n",
    "            if rmspe < best_loss:\n",
    "                print(f'new best:{rmspe}')\n",
    "                best_loss = rmspe\n",
    "                best_prediction = predictions\n",
    "                torch.save(model, os.path.join(output_dir, model_path.format(cv_idx)))\n",
    "\n",
    "        best_predictions.append(best_prediction)\n",
    "        best_losses.append(best_loss)\n",
    "        del model, train_dataset, valid_dataset, train_loader, valid_loader, X_tr, X_va, X_tr_cat, X_va_cat, y_tr, y_va, opt\n",
    "        if scheduler is not None:\n",
    "            del scheduler\n",
    "        gc.collect()\n",
    "\n",
    "    return best_losses, best_predictions, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T03:35:57.029334Z",
     "iopub.status.busy": "2022-01-23T03:35:56.898214Z",
     "iopub.status.idle": "2022-01-23T06:56:27.693883Z",
     "shell.execute_reply": "2022-01-23T06:56:27.695021Z",
     "shell.execute_reply.started": "2022-01-15T04:57:17.584692Z"
    },
    "papermill": {
     "duration": 12030.930352,
     "end_time": "2022-01-23T06:56:27.695345",
     "exception": false,
     "start_time": "2022-01-23T03:35:56.764993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 754/754 [00:08<00:00, 90.60it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 22.372, valid rmspe: 4.753\n",
      "new best:4.752574920654297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.11it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 5.762, valid rmspe: 1.034\n",
      "new best:1.0342416763305664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.78it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 6.080, valid rmspe: 1.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.12it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 1.859, valid rmspe: 0.263\n",
      "new best:0.2628456652164459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 215.67it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.884, valid rmspe: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.98it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.676, valid rmspe: 0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.45it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.484, valid rmspe: 0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.439, valid rmspe: 0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.412, valid rmspe: 0.229\n",
      "new best:0.2286132276058197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.99it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.437, valid rmspe: 0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.80it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.471, valid rmspe: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.53it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.468, valid rmspe: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.67it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.447, valid rmspe: 0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.434, valid rmspe: 0.224\n",
      "new best:0.22447380423545837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.73it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.372, valid rmspe: 0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.33it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.351, valid rmspe: 0.215\n",
      "new best:0.21536467969417572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.05it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.283, valid rmspe: 0.200\n",
      "new best:0.19959403574466705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.46it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.299, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.80it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.270, valid rmspe: 0.192\n",
      "new best:0.19241510331630707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.87it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.263, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.50it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.246, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.42it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.249, valid rmspe: 0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.67it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.236, valid rmspe: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.98it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 158.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.228, valid rmspe: 0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.00it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.216, valid rmspe: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.95it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 142.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.213, valid rmspe: 0.188\n",
      "new best:0.18794851005077362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.50it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.208, valid rmspe: 0.185\n",
      "new best:0.18493786454200745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.84it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.202, valid rmspe: 0.183\n",
      "new best:0.1826704740524292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.88it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.200, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.61it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.198, valid rmspe: 0.183\n",
      "model of seed 0 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.29it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 25.902, valid rmspe: 8.347\n",
      "new best:8.346624374389648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.927, valid rmspe: 3.117\n",
      "new best:3.117349624633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.017, valid rmspe: 1.863\n",
      "new best:1.8629391193389893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.95it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 1.479, valid rmspe: 0.264\n",
      "new best:0.2638780474662781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.05it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.691, valid rmspe: 0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.706, valid rmspe: 0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.533, valid rmspe: 0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.76it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.470, valid rmspe: 0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.94it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.414, valid rmspe: 0.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.69it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.379, valid rmspe: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.92it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.356, valid rmspe: 0.247\n",
      "new best:0.24733875691890717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.44it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.379, valid rmspe: 0.247\n",
      "new best:0.24679556488990784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.25it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.353, valid rmspe: 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.86it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.349, valid rmspe: 0.213\n",
      "new best:0.21286676824092865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.312, valid rmspe: 0.210\n",
      "new best:0.20974263548851013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.81it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.311, valid rmspe: 0.308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.56it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.384, valid rmspe: 0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.27it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.297, valid rmspe: 0.194\n",
      "new best:0.1935134381055832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 197.11it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.286, valid rmspe: 0.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.23it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.266, valid rmspe: 0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.39it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.249, valid rmspe: 0.193\n",
      "new best:0.19333338737487793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.35it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.241, valid rmspe: 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.11it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.234, valid rmspe: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.31it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 156.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.230, valid rmspe: 0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.61it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.215, valid rmspe: 0.183\n",
      "new best:0.18300898373126984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.03it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.206, valid rmspe: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.205, valid rmspe: 0.183\n",
      "new best:0.1825355887413025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.24it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.201, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.28it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.199, valid rmspe: 0.182\n",
      "new best:0.18239125609397888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.03it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.198, valid rmspe: 0.183\n",
      "model of seed 1 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 22.957, valid rmspe: 4.437\n",
      "new best:4.437321662902832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.71it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.313, valid rmspe: 5.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.87it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.243, valid rmspe: 4.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.62it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 2.395, valid rmspe: 1.107\n",
      "new best:1.1068626642227173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.84it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.930, valid rmspe: 0.728\n",
      "new best:0.7275764346122742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 198.64it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.724, valid rmspe: 0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.20it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.635, valid rmspe: 0.269\n",
      "new best:0.2685512602329254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.25it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.489, valid rmspe: 0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 198.10it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.548, valid rmspe: 0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.491, valid rmspe: 0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.33it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.414, valid rmspe: 0.223\n",
      "new best:0.22344279289245605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.77it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.418, valid rmspe: 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.407, valid rmspe: 0.213\n",
      "new best:0.21321535110473633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.89it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.415, valid rmspe: 0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.384, valid rmspe: 0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.04it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.349, valid rmspe: 0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.10it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.321, valid rmspe: 0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 214.62it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.301, valid rmspe: 0.196\n",
      "new best:0.19635164737701416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.297, valid rmspe: 0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.85it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.276, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.32it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.277, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.26it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.255, valid rmspe: 0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.19it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.244, valid rmspe: 0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.93it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.226, valid rmspe: 0.193\n",
      "new best:0.19260866940021515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.71it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.221, valid rmspe: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.95it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.210, valid rmspe: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.41it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 141.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.209, valid rmspe: 0.191\n",
      "new best:0.19114981591701508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.65it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.202, valid rmspe: 0.185\n",
      "new best:0.18460118770599365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.26it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.200, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.15it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.198, valid rmspe: 0.183\n",
      "new best:0.1826966106891632\n",
      "model of seed 2 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.13it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 25.893, valid rmspe: 4.976\n",
      "new best:4.975886821746826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 192.30it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 5.664, valid rmspe: 4.573\n",
      "new best:4.5726189613342285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.53it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 4.588, valid rmspe: 2.356\n",
      "new best:2.35612154006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.75it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 2.007, valid rmspe: 1.519\n",
      "new best:1.5186713933944702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.98it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.857, valid rmspe: 0.376\n",
      "new best:0.37629228830337524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.724, valid rmspe: 0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.54it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.632, valid rmspe: 0.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.94it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.632, valid rmspe: 0.259\n",
      "new best:0.25900837779045105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.562, valid rmspe: 0.224\n",
      "new best:0.22418265044689178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.55it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.574, valid rmspe: 0.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.86it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.548, valid rmspe: 0.268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.25it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.472, valid rmspe: 0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.92it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.471, valid rmspe: 0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.67it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.414, valid rmspe: 0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.20it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.369, valid rmspe: 0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.28it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.385, valid rmspe: 0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 142.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.352, valid rmspe: 0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.56it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.336, valid rmspe: 0.202\n",
      "new best:0.20245978236198425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 195.94it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.311, valid rmspe: 0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.76it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.300, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.272, valid rmspe: 0.232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.26it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.261, valid rmspe: 0.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.20it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.252, valid rmspe: 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.11it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.232, valid rmspe: 0.189\n",
      "new best:0.18899482488632202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.62it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.228, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.76it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.217, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.83it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.215, valid rmspe: 0.184\n",
      "new best:0.18358808755874634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.55it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.207, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.202, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 198.54it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.201, valid rmspe: 0.184\n",
      "model of seed 3 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.98it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 24.434, valid rmspe: 4.010\n",
      "new best:4.009545803070068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.43it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 8.192, valid rmspe: 5.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.35it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 4.852, valid rmspe: 1.279\n",
      "new best:1.278573751449585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.03it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 1.503, valid rmspe: 0.264\n",
      "new best:0.264295369386673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.16it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.730, valid rmspe: 0.254\n",
      "new best:0.2537139058113098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.679, valid rmspe: 0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.24it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.639, valid rmspe: 0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.36it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.580, valid rmspe: 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.86it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.577, valid rmspe: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.88it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.549, valid rmspe: 0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.17it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.495, valid rmspe: 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.58it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.387, valid rmspe: 0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.87it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.437, valid rmspe: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.19it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.399, valid rmspe: 0.228\n",
      "new best:0.22765451669692993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.31it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.345, valid rmspe: 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.338, valid rmspe: 0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.54it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.301, valid rmspe: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.64it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.283, valid rmspe: 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.39it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.286, valid rmspe: 0.206\n",
      "new best:0.20618575811386108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.99it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.262, valid rmspe: 0.184\n",
      "new best:0.18415620923042297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.46it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.244, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.242, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.82it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.234, valid rmspe: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.68it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.226, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.219, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.14it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.206, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 197.72it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.207, valid rmspe: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.42it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.201, valid rmspe: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.198, valid rmspe: 0.184\n",
      "new best:0.18403522670269012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.54it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.198, valid rmspe: 0.183\n",
      "new best:0.18262185156345367\n",
      "model of seed 4 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.68it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 27.567, valid rmspe: 5.724\n",
      "new best:5.724095821380615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.14it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.468, valid rmspe: 7.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.12it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.987, valid rmspe: 1.873\n",
      "new best:1.8731366395950317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 2.408, valid rmspe: 1.145\n",
      "new best:1.1449710130691528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 1.156, valid rmspe: 0.400\n",
      "new best:0.40017247200012207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.34it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.777, valid rmspe: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.77it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.623, valid rmspe: 0.302\n",
      "new best:0.3018873333930969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.52it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.498, valid rmspe: 0.467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.50it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.524, valid rmspe: 0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.64it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.448, valid rmspe: 0.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.91it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.429, valid rmspe: 0.302\n",
      "new best:0.30161017179489136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.380, valid rmspe: 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.58it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.403, valid rmspe: 0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.69it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.362, valid rmspe: 0.228\n",
      "new best:0.2278258055448532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.89it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 156.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.314, valid rmspe: 0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.36it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.308, valid rmspe: 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.51it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.296, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.91it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.276, valid rmspe: 0.205\n",
      "new best:0.20462577044963837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.280, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.65it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.264, valid rmspe: 0.203\n",
      "new best:0.20276771485805511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.64it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 141.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.242, valid rmspe: 0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.50it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 141.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.231, valid rmspe: 0.186\n",
      "new best:0.18634337186813354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 139.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.228, valid rmspe: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.84it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.216, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.51it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.212, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.30it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.218, valid rmspe: 0.186\n",
      "new best:0.18572302162647247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.69it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.208, valid rmspe: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 156.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.201, valid rmspe: 0.183\n",
      "new best:0.1830705851316452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.74it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.200, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.04it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.199, valid rmspe: 0.183\n",
      "new best:0.18277326226234436\n",
      "model of seed 5 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.38it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 141.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 24.179, valid rmspe: 2.533\n",
      "new best:2.533374309539795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.312, valid rmspe: 8.727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 215.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.375, valid rmspe: 1.430\n",
      "new best:1.4298818111419678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.94it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 1.786, valid rmspe: 0.315\n",
      "new best:0.31544557213783264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.26it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.789, valid rmspe: 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.61it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.771, valid rmspe: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.682, valid rmspe: 1.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.466, valid rmspe: 0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.429, valid rmspe: 0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.96it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.452, valid rmspe: 0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.20it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.454, valid rmspe: 0.236\n",
      "new best:0.23614445328712463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.389, valid rmspe: 0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.50it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.361, valid rmspe: 0.339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.87it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.368, valid rmspe: 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.34it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.382, valid rmspe: 0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.02it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.323, valid rmspe: 0.211\n",
      "new best:0.21069465577602386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.56it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.305, valid rmspe: 0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.94it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.272, valid rmspe: 0.309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:05<00:00, 131.50it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.305, valid rmspe: 0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.58it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.264, valid rmspe: 0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.41it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.239, valid rmspe: 0.188\n",
      "new best:0.18772175908088684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 195.13it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.239, valid rmspe: 0.183\n",
      "new best:0.18331533670425415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.45it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 156.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.226, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 139.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.226, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.82it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.213, valid rmspe: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.18it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.210, valid rmspe: 0.182\n",
      "new best:0.18239997327327728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 198.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.205, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.46it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.201, valid rmspe: 0.182\n",
      "new best:0.18187078833580017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.64it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.198, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.198, valid rmspe: 0.183\n",
      "model of seed 6 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:05<00:00, 143.86it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 23.697, valid rmspe: 3.496\n",
      "new best:3.495781898498535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.42it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 5.203, valid rmspe: 3.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.91it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.237, valid rmspe: 2.335\n",
      "new best:2.3347554206848145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.78it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 2.288, valid rmspe: 1.223\n",
      "new best:1.2227176427841187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.51it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.788, valid rmspe: 0.714\n",
      "new best:0.7140625715255737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.72it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.574, valid rmspe: 0.391\n",
      "new best:0.39139053225517273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.85it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.526, valid rmspe: 0.430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.547, valid rmspe: 0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.13it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.462, valid rmspe: 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.69it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.554, valid rmspe: 0.336\n",
      "new best:0.3361545205116272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.73it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.516, valid rmspe: 0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.84it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.465, valid rmspe: 0.470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.05it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.428, valid rmspe: 0.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.21it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.335, valid rmspe: 0.381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.34it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.312, valid rmspe: 0.315\n",
      "new best:0.3146698474884033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.90it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.315, valid rmspe: 0.213\n",
      "new best:0.21320806443691254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.39it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.290, valid rmspe: 0.191\n",
      "new best:0.19113920629024506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.98it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.301, valid rmspe: 0.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.08it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.290, valid rmspe: 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 196.96it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.260, valid rmspe: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.78it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.248, valid rmspe: 0.252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.16it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.233, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.42it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.228, valid rmspe: 0.184\n",
      "new best:0.18380025029182434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.25it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 141.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.225, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 214.99it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.208, valid rmspe: 0.183\n",
      "new best:0.18336494266986847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.82it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.210, valid rmspe: 0.183\n",
      "new best:0.18260619044303894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.05it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.203, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.33it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.201, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.80it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.198, valid rmspe: 0.182\n",
      "new best:0.18225085735321045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.67it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.197, valid rmspe: 0.182\n",
      "new best:0.1822158396244049\n",
      "model of seed 7 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.99it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 142.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 24.316, valid rmspe: 6.537\n",
      "new best:6.536843776702881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.91it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.763, valid rmspe: 4.523\n",
      "new best:4.523130416870117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.95it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.890, valid rmspe: 3.080\n",
      "new best:3.0799803733825684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.52it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 2.238, valid rmspe: 0.589\n",
      "new best:0.5893601179122925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.07it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 1.029, valid rmspe: 0.391\n",
      "new best:0.39055144786834717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.39it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.674, valid rmspe: 0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 193.70it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.534, valid rmspe: 0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.28it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.627, valid rmspe: 0.276\n",
      "new best:0.2758009433746338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.532, valid rmspe: 0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.17it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.380, valid rmspe: 0.216\n",
      "new best:0.21557816863059998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.59it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.456, valid rmspe: 0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.18it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.372, valid rmspe: 0.682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.47it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.446, valid rmspe: 0.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 215.47it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.380, valid rmspe: 0.188\n",
      "new best:0.18775807321071625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.43it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.323, valid rmspe: 0.407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.70it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.354, valid rmspe: 0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.43it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 142.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.335, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.00it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.281, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.92it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.286, valid rmspe: 0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.75it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.265, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.57it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 156.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.252, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.06it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.246, valid rmspe: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.22it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.226, valid rmspe: 0.186\n",
      "new best:0.18640480935573578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.19it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.221, valid rmspe: 0.185\n",
      "new best:0.18503782153129578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.216, valid rmspe: 0.185\n",
      "new best:0.18489444255828857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.211, valid rmspe: 0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 213.72it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.207, valid rmspe: 0.183\n",
      "new best:0.18291930854320526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 212.82it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 153.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.200, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 194.73it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.199, valid rmspe: 0.182\n",
      "new best:0.18224793672561646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.26it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.197, valid rmspe: 0.182\n",
      "model of seed 8 added.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.85it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 24.461, valid rmspe: 5.369\n",
      "new best:5.369041442871094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 202.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.939, valid rmspe: 7.630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.54it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.036, valid rmspe: 4.001\n",
      "new best:4.001275539398193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 209.79it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 150.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 1.536, valid rmspe: 0.589\n",
      "new best:0.5894321799278259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.92it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 156.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 0.843, valid rmspe: 0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 214.28it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 0.548, valid rmspe: 0.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.05it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 0.654, valid rmspe: 0.562\n",
      "new best:0.5623127222061157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 199.45it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 134.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 0.516, valid rmspe: 0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.35it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 0.589, valid rmspe: 0.247\n",
      "new best:0.2467920184135437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 196.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.573, valid rmspe: 0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.72it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 157.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.425, valid rmspe: 0.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.69it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.440, valid rmspe: 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.53it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.455, valid rmspe: 0.226\n",
      "new best:0.22616133093833923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 203.86it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.414, valid rmspe: 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.383, valid rmspe: 0.208\n",
      "new best:0.2077070027589798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 207.52it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.363, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 204.26it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 149.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.337, valid rmspe: 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.14it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.337, valid rmspe: 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.66it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 146.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.293, valid rmspe: 0.303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 201.68it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.296, valid rmspe: 0.199\n",
      "new best:0.1987466961145401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.83it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 154.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.249, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.80it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 151.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.246, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 205.37it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 155.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.231, valid rmspe: 0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 214.14it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.226, valid rmspe: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 206.64it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 144.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.217, valid rmspe: 0.191\n",
      "new best:0.19092558324337006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.09it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 145.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.214, valid rmspe: 0.184\n",
      "new best:0.18419314920902252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 208.48it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 143.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.206, valid rmspe: 0.183\n",
      "new best:0.18282920122146606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 200.93it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 152.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.202, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 210.80it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 148.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.200, valid rmspe: 0.183\n",
      "new best:0.18282321095466614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████████| 754/754 [00:03<00:00, 211.97it/s]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 147.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.199, valid rmspe: 0.183\n",
      "model of seed 9 added.\n",
      "scores(sorted): [0.18187079, 0.18221584, 0.18224794, 0.18239126, 0.18262185, 0.18267047, 0.18269661, 0.18277326, 0.18282321, 0.18358809]\n",
      "total 3 models will be used.\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 78.28it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 32.011, valid rmspe: 5.435\n",
      "new best:5.434852600097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.02it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 5.691, valid rmspe: 6.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.86it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.749, valid rmspe: 2.317\n",
      "new best:2.317324161529541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 6.710, valid rmspe: 4.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.68it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 6.610, valid rmspe: 5.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.66it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 5.155, valid rmspe: 3.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.52it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 2.866, valid rmspe: 2.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.47it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 2.384, valid rmspe: 3.866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.733, valid rmspe: 0.916\n",
      "new best:0.9155956506729126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.683, valid rmspe: 2.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.027, valid rmspe: 0.690\n",
      "new best:0.690470814704895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.95it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.591, valid rmspe: 0.331\n",
      "new best:0.330839067697525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 1.372, valid rmspe: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.68it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.807, valid rmspe: 0.255\n",
      "new best:0.25483500957489014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.80it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.751, valid rmspe: 0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 53.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.626, valid rmspe: 0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.17it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.543, valid rmspe: 0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.08it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.547, valid rmspe: 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.514, valid rmspe: 0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.88it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 53.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.444, valid rmspe: 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.91it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.703, valid rmspe: 0.244\n",
      "new best:0.24439100921154022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.46it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.455, valid rmspe: 0.241\n",
      "new best:0.24074505269527435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.26it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.471, valid rmspe: 0.233\n",
      "new best:0.23265387117862701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.32it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.434, valid rmspe: 0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.71it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.488, valid rmspe: 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.55it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.407, valid rmspe: 0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.422, valid rmspe: 0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.73it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.400, valid rmspe: 0.193\n",
      "new best:0.19321514666080475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.512, valid rmspe: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.46it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.403, valid rmspe: 0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.58it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.515, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.331, valid rmspe: 0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.324, valid rmspe: 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.77it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.334, valid rmspe: 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.65it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.311, valid rmspe: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.88it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 53.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.297, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.236, valid rmspe: 0.184\n",
      "new best:0.18428613245487213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.87it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.220, valid rmspe: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.222, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 85.58it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.218, valid rmspe: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.64it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.215, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.07it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.208, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.73it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.212, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.95it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.205, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.210, valid rmspe: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.14it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.209, valid rmspe: 0.197\n",
      "Epoch 00046: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.49it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.197, valid rmspe: 0.183\n",
      "new best:0.1831127554178238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.197, valid rmspe: 0.182\n",
      "new best:0.18160590529441833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.68it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.196, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.196, valid rmspe: 0.187\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.19it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 36.659, valid rmspe: 9.809\n",
      "new best:9.808764457702637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.18it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 7.696, valid rmspe: 7.764\n",
      "new best:7.76447868347168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.07it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 6.037, valid rmspe: 2.815\n",
      "new best:2.815337896347046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.75it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 4.338, valid rmspe: 3.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.68it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 2.592, valid rmspe: 1.189\n",
      "new best:1.1893701553344727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 3.535, valid rmspe: 4.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.99it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 53.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 2.568, valid rmspe: 1.390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.55it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 2.140, valid rmspe: 1.654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.31it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.291, valid rmspe: 1.166\n",
      "new best:1.1661964654922485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.16it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.645, valid rmspe: 0.389\n",
      "new best:0.38901281356811523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.254, valid rmspe: 0.191\n",
      "new best:0.19132860004901886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.69it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.225, valid rmspe: 0.188\n",
      "new best:0.1882178634405136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.219, valid rmspe: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.06it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.215, valid rmspe: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.56it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.210, valid rmspe: 0.188\n",
      "new best:0.18778207898139954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.49it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.208, valid rmspe: 0.187\n",
      "new best:0.186654195189476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.73it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.205, valid rmspe: 0.185\n",
      "new best:0.18501520156860352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.26it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.209, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.50it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.213, valid rmspe: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.35it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.210, valid rmspe: 0.203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.210, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.88it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.207, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.209, valid rmspe: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.28it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.205, valid rmspe: 0.183\n",
      "new best:0.1832500398159027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.86it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.213, valid rmspe: 0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.21it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.212, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.36it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.208, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.51it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.207, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.75it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.211, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.206, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.206, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.55it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.207, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.204, valid rmspe: 0.183\n",
      "new best:0.18272265791893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.65it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.210, valid rmspe: 0.182\n",
      "new best:0.18238003551959991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.209, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.91it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.213, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.83it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 52.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.205, valid rmspe: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.42it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.210, valid rmspe: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.75it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.204, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.208, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.219, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.08it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.208, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.44it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.214, valid rmspe: 0.233\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.42it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.201, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.90it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.197, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.197, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.196, valid rmspe: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.92it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.196, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.71it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.195, valid rmspe: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.53it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.196, valid rmspe: 0.185\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 86.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 27.461, valid rmspe: 10.909\n",
      "new best:10.908787727355957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.841, valid rmspe: 6.189\n",
      "new best:6.189023971557617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.05it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 6.574, valid rmspe: 4.358\n",
      "new best:4.357969760894775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.84it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 5.495, valid rmspe: 5.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.08it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 3.981, valid rmspe: 3.849\n",
      "new best:3.8491322994232178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.87it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 3.304, valid rmspe: 2.716\n",
      "new best:2.716344118118286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.26it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 2.693, valid rmspe: 3.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 2.078, valid rmspe: 2.096\n",
      "new best:2.096144199371338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.39it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.849, valid rmspe: 0.986\n",
      "new best:0.9858832359313965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 86.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.566, valid rmspe: 0.702\n",
      "new best:0.7020903825759888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 84.59it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.838, valid rmspe: 0.440\n",
      "new best:0.44046929478645325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.33it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.983, valid rmspe: 1.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.42it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.639, valid rmspe: 0.329\n",
      "new best:0.3291741609573364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.95it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.745, valid rmspe: 0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.42it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.638, valid rmspe: 0.270\n",
      "new best:0.26968348026275635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.21it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.443, valid rmspe: 0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.520, valid rmspe: 0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.57it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.493, valid rmspe: 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.59it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.424, valid rmspe: 0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.78it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.427, valid rmspe: 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.584, valid rmspe: 0.202\n",
      "new best:0.2021435797214508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.77it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.379, valid rmspe: 0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.561, valid rmspe: 0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.64it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.447, valid rmspe: 0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.27it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.525, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.55it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.351, valid rmspe: 0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.09it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.319, valid rmspe: 0.192\n",
      "new best:0.19154317677021027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.57it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.258, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.28it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.306, valid rmspe: 0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.92it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.238, valid rmspe: 0.191\n",
      "new best:0.191110298037529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.89it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.210, valid rmspe: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.05it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.215, valid rmspe: 0.187\n",
      "new best:0.18705683946609497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.73it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.209, valid rmspe: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.65it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.212, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.93it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.211, valid rmspe: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.94it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.207, valid rmspe: 0.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.208, valid rmspe: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.203, valid rmspe: 0.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.202, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.46it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.204, valid rmspe: 0.186\n",
      "new best:0.185514897108078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.212, valid rmspe: 0.218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.26it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.206, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.20it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.209, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.09it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.208, valid rmspe: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.10it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.208, valid rmspe: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.62it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.207, valid rmspe: 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.81it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.212, valid rmspe: 0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.24it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.203, valid rmspe: 0.182\n",
      "new best:0.18225373327732086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.33it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.209, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.62it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.205, valid rmspe: 0.194\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.09it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 33.598, valid rmspe: 8.641\n",
      "new best:8.640730857849121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 7.005, valid rmspe: 2.823\n",
      "new best:2.8233633041381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.08it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.668, valid rmspe: 2.216\n",
      "new best:2.215566635131836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 4.878, valid rmspe: 2.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.70it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 4.113, valid rmspe: 5.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 3.131, valid rmspe: 1.497\n",
      "new best:1.4967825412750244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.50it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 2.446, valid rmspe: 1.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 1.725, valid rmspe: 2.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.793, valid rmspe: 2.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.29it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.612, valid rmspe: 2.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.01it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.517, valid rmspe: 1.433\n",
      "new best:1.4329237937927246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.86it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.186, valid rmspe: 0.515\n",
      "new best:0.515132486820221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.811, valid rmspe: 0.675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.57it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.791, valid rmspe: 1.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.11it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.613, valid rmspe: 0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.31it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.651, valid rmspe: 1.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.34it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.609, valid rmspe: 0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.93it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.474, valid rmspe: 0.214\n",
      "new best:0.21387527883052826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.64it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.443, valid rmspe: 0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.55it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.495, valid rmspe: 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.548, valid rmspe: 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.03it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.418, valid rmspe: 0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.10it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.417, valid rmspe: 0.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.32it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.364, valid rmspe: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 94.02it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.395, valid rmspe: 0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.350, valid rmspe: 0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.03it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.474, valid rmspe: 0.239\n",
      "Epoch 00027: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.80it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.246, valid rmspe: 0.187\n",
      "new best:0.186580091714859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.14it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.239, valid rmspe: 0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.97it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.250, valid rmspe: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.27it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.231, valid rmspe: 0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.248, valid rmspe: 0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.76it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.259, valid rmspe: 0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.73it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.249, valid rmspe: 0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.243, valid rmspe: 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.46it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.294, valid rmspe: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.28it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.228, valid rmspe: 0.200\n",
      "Epoch 00037: reducing learning rate of group 0 to 3.4200e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.204, valid rmspe: 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.80it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.201, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.200, valid rmspe: 0.183\n",
      "new best:0.18317784368991852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.86it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.198, valid rmspe: 0.183\n",
      "new best:0.1827765703201294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.16it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.203, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.70it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.200, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.26it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.207, valid rmspe: 0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.81it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.199, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.201, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.96it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.198, valid rmspe: 0.182\n",
      "new best:0.18219619989395142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.28it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.198, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.36it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.196, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.29it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.198, valid rmspe: 0.182\n",
      "new best:0.1816108524799347\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 32.964, valid rmspe: 5.996\n",
      "new best:5.995574474334717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.01it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.580, valid rmspe: 4.318\n",
      "new best:4.317722797393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 4.930, valid rmspe: 2.141\n",
      "new best:2.140641927719116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.55it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 3.526, valid rmspe: 3.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.58it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 3.391, valid rmspe: 2.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 2.264, valid rmspe: 1.956\n",
      "new best:1.956201195716858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 2.115, valid rmspe: 1.791\n",
      "new best:1.7911927700042725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 1.881, valid rmspe: 2.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.72it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.708, valid rmspe: 1.159\n",
      "new best:1.159364938735962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.10it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.517, valid rmspe: 0.911\n",
      "new best:0.9107974767684937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.10it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 1.499, valid rmspe: 0.490\n",
      "new best:0.49042508006095886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.93it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 1.265, valid rmspe: 3.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 1.830, valid rmspe: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.47it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 1.423, valid rmspe: 0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.67it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.984, valid rmspe: 0.390\n",
      "new best:0.39025428891181946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.36it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.959, valid rmspe: 0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.57it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.776, valid rmspe: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.69it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.686, valid rmspe: 1.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.670, valid rmspe: 1.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.65it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.757, valid rmspe: 0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.59it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.554, valid rmspe: 1.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.53it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.624, valid rmspe: 0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.81it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.565, valid rmspe: 0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 86.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.698, valid rmspe: 0.847\n",
      "Epoch 00024: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.39it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.270, valid rmspe: 0.206\n",
      "new best:0.20565970242023468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.277, valid rmspe: 0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.23it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.243, valid rmspe: 0.204\n",
      "new best:0.20354542136192322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.66it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.249, valid rmspe: 0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.244, valid rmspe: 0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.78it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.249, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.66it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 53.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.260, valid rmspe: 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.19it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.250, valid rmspe: 0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.05it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.270, valid rmspe: 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.238, valid rmspe: 0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.70it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.249, valid rmspe: 0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.97it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.260, valid rmspe: 0.483\n",
      "Epoch 00036: reducing learning rate of group 0 to 3.4200e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.12it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.204, valid rmspe: 0.267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.10it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.202, valid rmspe: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.69it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.203, valid rmspe: 0.185\n",
      "new best:0.18506699800491333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.89it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.201, valid rmspe: 0.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.203, valid rmspe: 0.214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.207, valid rmspe: 0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.36it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.203, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.58it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.203, valid rmspe: 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.61it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.204, valid rmspe: 0.250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.42it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.202, valid rmspe: 0.184\n",
      "new best:0.18357595801353455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.56it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.203, valid rmspe: 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.65it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.201, valid rmspe: 0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.206, valid rmspe: 0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.90it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.199, valid rmspe: 0.441\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.77it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 33.783, valid rmspe: 5.303\n",
      "new best:5.302620887756348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.89it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.648, valid rmspe: 4.996\n",
      "new best:4.996073246002197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.29it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.703, valid rmspe: 2.259\n",
      "new best:2.258941411972046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.98it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 4.393, valid rmspe: 4.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.75it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 3.910, valid rmspe: 1.105\n",
      "new best:1.1048437356948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 2.042, valid rmspe: 1.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.30it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 2.582, valid rmspe: 2.953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.51it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 2.014, valid rmspe: 0.910\n",
      "new best:0.9102892279624939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.690, valid rmspe: 2.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.088, valid rmspe: 2.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.77it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.752, valid rmspe: 1.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.715, valid rmspe: 0.489\n",
      "new best:0.4890424311161041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.58it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.623, valid rmspe: 0.263\n",
      "new best:0.2630673348903656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.94it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.453, valid rmspe: 0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.10it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.359, valid rmspe: 0.226\n",
      "new best:0.22557856142520905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.17it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.296, valid rmspe: 0.208\n",
      "new best:0.20817847549915314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.00it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.270, valid rmspe: 0.202\n",
      "new best:0.2018660008907318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.68it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.230, valid rmspe: 0.187\n",
      "new best:0.18727557361125946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.27it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.215, valid rmspe: 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.211, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.209, valid rmspe: 0.222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 86.59it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.211, valid rmspe: 0.186\n",
      "new best:0.18601444363594055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.219, valid rmspe: 0.186\n",
      "new best:0.18559236824512482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.209, valid rmspe: 0.185\n",
      "new best:0.18502582609653473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.62it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.208, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.91it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.236, valid rmspe: 0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.33it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.211, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.14it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.208, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.07it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.207, valid rmspe: 0.230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.212, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.51it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.211, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.64it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.208, valid rmspe: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.210, valid rmspe: 0.183\n",
      "new best:0.18295958638191223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.206, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 53.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.212, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.59it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.208, valid rmspe: 0.270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.62it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.219, valid rmspe: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.71it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.211, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.35it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.211, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.22it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.212, valid rmspe: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 60.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.208, valid rmspe: 0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 86.83it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.210, valid rmspe: 0.233\n",
      "Epoch 00042: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.95it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.200, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.40it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.198, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.80it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.198, valid rmspe: 0.182\n",
      "new best:0.1819935142993927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.63it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.197, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.37it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.196, valid rmspe: 0.181\n",
      "new best:0.18113702535629272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.04it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.197, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.15it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.196, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.14it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.196, valid rmspe: 0.183\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.15it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 26.521, valid rmspe: 6.767\n",
      "new best:6.766728401184082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.79it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.718, valid rmspe: 6.047\n",
      "new best:6.0465826988220215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.65it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.405, valid rmspe: 3.706\n",
      "new best:3.7056326866149902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 4.616, valid rmspe: 2.601\n",
      "new best:2.6006622314453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 94.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 3.880, valid rmspe: 3.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.81it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 4.798, valid rmspe: 5.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.68it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 3.050, valid rmspe: 2.236\n",
      "new best:2.235947608947754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.81it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 1.917, valid rmspe: 0.901\n",
      "new best:0.9010453820228577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.79it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.446, valid rmspe: 0.807\n",
      "new best:0.8074859380722046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.41it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 0.994, valid rmspe: 0.415\n",
      "new best:0.41488319635391235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.72it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.837, valid rmspe: 0.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.08it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.571, valid rmspe: 0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.53it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.411, valid rmspe: 0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.85it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.466, valid rmspe: 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.01it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.327, valid rmspe: 0.251\n",
      "new best:0.25086069107055664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.28it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.307, valid rmspe: 0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.263, valid rmspe: 0.194\n",
      "new best:0.1943490207195282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.78it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.224, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 85.93it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.217, valid rmspe: 0.209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.214, valid rmspe: 0.228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.21it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.212, valid rmspe: 0.185\n",
      "new best:0.1846567690372467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.204, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.21it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.209, valid rmspe: 0.183\n",
      "new best:0.18311701714992523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.212, valid rmspe: 0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.83it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.207, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.205, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.52it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.211, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.60it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.208, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.34it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.206, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.59it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.209, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.98it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.205, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.80it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.206, valid rmspe: 0.183\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.1400e-04.\n",
      "new best:0.18310758471488953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.58it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.197, valid rmspe: 0.182\n",
      "new best:0.18218429386615753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.79it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.197, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.11it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.196, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.97it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.195, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 88.14it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.195, valid rmspe: 0.182\n",
      "new best:0.18163545429706573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.50it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.197, valid rmspe: 0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.08it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.195, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.05it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.194, valid rmspe: 0.181\n",
      "new best:0.18136703968048096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.79it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.194, valid rmspe: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.56it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.196, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.52it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.195, valid rmspe: 0.181\n",
      "new best:0.1811065375804901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.21it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.197, valid rmspe: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.70it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.194, valid rmspe: 0.193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.44it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.195, valid rmspe: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.194, valid rmspe: 0.181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.13it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.194, valid rmspe: 0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.33it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.195, valid rmspe: 0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.195, valid rmspe: 0.195\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 30.892, valid rmspe: 3.113\n",
      "new best:3.1133017539978027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.42it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 6.168, valid rmspe: 5.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.56it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.935, valid rmspe: 6.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train loss: 5.022, valid rmspe: 4.163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train loss: 4.379, valid rmspe: 2.854\n",
      "new best:2.854027271270752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.15it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train loss: 4.814, valid rmspe: 6.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.24it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train loss: 4.346, valid rmspe: 2.085\n",
      "new best:2.085439920425415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.20it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train loss: 2.107, valid rmspe: 0.527\n",
      "new best:0.5265272259712219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.97it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train loss: 1.489, valid rmspe: 1.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.52it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train loss: 1.223, valid rmspe: 0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.74it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train loss: 0.686, valid rmspe: 1.150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train loss: 0.624, valid rmspe: 0.275\n",
      "new best:0.2751053273677826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.26it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train loss: 0.470, valid rmspe: 0.251\n",
      "new best:0.25128352642059326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.25it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train loss: 0.360, valid rmspe: 0.246\n",
      "new best:0.24579352140426636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.66it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train loss: 0.357, valid rmspe: 0.235\n",
      "new best:0.23496463894844055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train loss: 0.332, valid rmspe: 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.49it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train loss: 0.288, valid rmspe: 0.193\n",
      "new best:0.19286619126796722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.48it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train loss: 0.233, valid rmspe: 0.189\n",
      "new best:0.1888381689786911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.03it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train loss: 0.215, valid rmspe: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train loss: 0.220, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.18it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train loss: 0.229, valid rmspe: 0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.47it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, train loss: 0.213, valid rmspe: 0.187\n",
      "new best:0.1866985559463501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.38it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, train loss: 0.218, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.63it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, train loss: 0.208, valid rmspe: 0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.43it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, train loss: 0.209, valid rmspe: 0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.93it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 55.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, train loss: 0.215, valid rmspe: 0.197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.67it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, train loss: 0.216, valid rmspe: 0.184\n",
      "new best:0.18374647200107574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.06it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, train loss: 0.212, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.69it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, train loss: 0.207, valid rmspe: 0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.20it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, train loss: 0.207, valid rmspe: 0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.73it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, train loss: 0.209, valid rmspe: 0.183\n",
      "new best:0.18316683173179626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.12it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, train loss: 0.208, valid rmspe: 0.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.57it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, train loss: 0.208, valid rmspe: 0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.75it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, train loss: 0.206, valid rmspe: 0.183\n",
      "new best:0.1827247142791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.86it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, train loss: 0.206, valid rmspe: 0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.69it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, train loss: 0.210, valid rmspe: 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.31it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, train loss: 0.214, valid rmspe: 0.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 90.12it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, train loss: 0.210, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 87.93it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, train loss: 0.208, valid rmspe: 0.190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.45it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, train loss: 0.212, valid rmspe: 0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 94.46it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, train loss: 0.210, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.33it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, train loss: 0.205, valid rmspe: 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.50it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, train loss: 0.212, valid rmspe: 0.205\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.1400e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.53it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, train loss: 0.198, valid rmspe: 0.183\n",
      "new best:0.18250463902950287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.62it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, train loss: 0.196, valid rmspe: 0.182\n",
      "new best:0.18198296427726746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.67it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 59.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, train loss: 0.198, valid rmspe: 0.181\n",
      "new best:0.18129046261310577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.07it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, train loss: 0.195, valid rmspe: 0.182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 93.20it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 56.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, train loss: 0.196, valid rmspe: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 89.96it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 54.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, train loss: 0.195, valid rmspe: 0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 94.23it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, train loss: 0.194, valid rmspe: 0.181\n",
      "fold 0 train: (386036, 591), valid: (42896, 591)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.19it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 57.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 33.680, valid rmspe: 7.587\n",
      "new best:7.587121963500977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 92.54it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 8.401, valid rmspe: 10.065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████| 302/302 [00:03<00:00, 91.82it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 34/34 [00:00<00:00, 58.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train loss: 5.556, valid rmspe: 1.447\n",
      "new best:1.4471641778945923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|██████████████████████████████████████████████████████████▊    | 282/302 [00:02<00:00, 105.16it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "del df, df_train\n",
    "gc.collect()\n",
    "\n",
    "def get_top_n_models(models, scores, top_n):\n",
    "    if len(models) <= top_n:\n",
    "        print('number of models are less than top_n. all models will be used')\n",
    "        return models\n",
    "    sorted_ = [(y, x) for y, x in sorted(zip(scores, models), key=lambda pair: pair[0])]\n",
    "    print(f'scores(sorted): {[y for y, _ in sorted_]}')\n",
    "    return [x for _, x in sorted_][:top_n]\n",
    "\n",
    "\n",
    "if PREDICT_MLP:\n",
    "    model_paths = []\n",
    "    scores = []\n",
    "    \n",
    "    if SHORTCUT_NN_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "        print('shortcut to save quota...')\n",
    "        epochs = 3\n",
    "        valid_th = 100\n",
    "    else:\n",
    "        epochs = 30\n",
    "        valid_th = NN_VALID_TH\n",
    "    \n",
    "    for i in range(NN_NUM_MODELS):\n",
    "        # MLP\n",
    "        nn_losses, nn_preds, scaler = train_nn(X, y, \n",
    "                                               [folds[-1]], \n",
    "                                               device=device, \n",
    "                                               batch_size=512,\n",
    "                                               mlp_bn=True,\n",
    "                                               mlp_hidden=256,\n",
    "                                               mlp_dropout=0.0,\n",
    "                                               emb_dim=30,\n",
    "                                               epochs=epochs,\n",
    "                                               lr=0.002,\n",
    "                                               max_lr=0.0055,\n",
    "                                               weight_decay=1e-7,\n",
    "                                               model_path='mlp_fold_{}' + f\"_seed{i}.pth\",\n",
    "                                               seed=i)\n",
    "        if nn_losses[0] < NN_VALID_TH:\n",
    "            print(f'model of seed {i} added.')\n",
    "            scores.append(nn_losses[0])\n",
    "            model_paths.append(f'artifacts/mlp_fold_0_seed{i}.pth')\n",
    "            np.save(f'pred_mlp_seed{i}.npy', nn_preds[0])\n",
    "\n",
    "    model_paths = get_top_n_models(model_paths, scores, NN_MODEL_TOP_N)\n",
    "    mlp_model = [torch.load(path, device) for path in model_paths]\n",
    "    print(f'total {len(mlp_model)} models will be used.')\n",
    "if PREDICT_CNN:\n",
    "    model_paths = []\n",
    "    scores = []\n",
    "        \n",
    "    if SHORTCUT_NN_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "        print('shortcut to save quota...')\n",
    "        epochs = 3\n",
    "        valid_th = 100\n",
    "    else:\n",
    "        epochs = 50\n",
    "        valid_th = NN_VALID_TH\n",
    "\n",
    "    for i in range(NN_NUM_MODELS):\n",
    "        nn_losses, nn_preds, scaler = train_nn(X, y, \n",
    "                                               [folds[-1]], \n",
    "                                               device=device, \n",
    "                                               cnn_hidden=8*128,\n",
    "                                               batch_size=1280,\n",
    "                                               model_type='cnn',\n",
    "                                               emb_dim=30,\n",
    "                                               epochs=epochs, #epochs,\n",
    "                                               cnn_channel1=128,\n",
    "                                               cnn_channel2=3*128,\n",
    "                                               cnn_channel3=3*128,\n",
    "                                               lr=0.00038, #0.0011,\n",
    "                                               max_lr=0.0013,\n",
    "                                               weight_decay=6.5e-6,\n",
    "                                               optimizer_type='adam',\n",
    "                                               scheduler_type='reduce',\n",
    "                                               model_path='cnn_fold_{}' + f\"_seed{i}.pth\",\n",
    "                                               seed=i,\n",
    "                                               cnn_dropout=0.0,\n",
    "                                               cnn_weight_norm=True,\n",
    "                                               cnn_leaky_relu=False,\n",
    "                                               patience=8,\n",
    "                                               factor=0.3)\n",
    "        if nn_losses[0] < valid_th:\n",
    "            model_paths.append(f'artifacts/cnn_fold_0_seed{i}.pth')\n",
    "            scores.append(nn_losses[0])\n",
    "            np.save(f'pred_cnn_seed{i}.npy', nn_preds[0])\n",
    "            \n",
    "    model_paths = get_top_n_models(model_paths, scores, NN_MODEL_TOP_N)\n",
    "    cnn_model = [torch.load(path, device) for path in model_paths]\n",
    "    print(f'total {len(cnn_model)} models will be used.')\n",
    "    \n",
    "if PREDICT_TABNET:\n",
    "    tab_model = []\n",
    "    scores = []\n",
    "        \n",
    "    if SHORTCUT_NN_IN_1ST_STAGE and IS_1ST_STAGE:\n",
    "        print('shortcut to save quota...')\n",
    "        epochs = 10\n",
    "        valid_th = 1000\n",
    "    else:\n",
    "        print('train full')\n",
    "        epochs = 250\n",
    "        valid_th = NN_VALID_TH\n",
    "\n",
    "    for i in range(TABNET_NUM_MODELS):\n",
    "        nn_losses, nn_preds, scaler, model = train_tabnet(X, y,  \n",
    "                                                          [folds[-1]], \n",
    "                                                          batch_size=1280,\n",
    "                                                          epochs=epochs, #epochs,\n",
    "                                                          lr=0.04,\n",
    "                                                          patience=50,\n",
    "                                                          factor=0.5,\n",
    "                                                          gamma=1.6,\n",
    "                                                          lambda_sparse=3.55e-6,\n",
    "                                                          seed=i,\n",
    "                                                          n_a=36)\n",
    "        if nn_losses[0] < valid_th:\n",
    "            tab_model.append(model)\n",
    "            scores.append(nn_losses[0])\n",
    "            np.save(f'pred_tab_seed{i}.npy', nn_preds[0])\n",
    "            model.save_model(f'artifacts/tabnet_fold_0_seed{i}')\n",
    "            \n",
    "    tab_model = get_top_n_models(tab_model, scores, TAB_MODEL_TOP_N)\n",
    "    print(f'total {len(tab_model)} models will be used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T06:57:18.576429Z",
     "iopub.status.busy": "2022-01-23T06:57:18.575179Z",
     "iopub.status.idle": "2022-01-23T06:57:18.578624Z",
     "shell.execute_reply": "2022-01-23T06:57:18.579071Z",
     "shell.execute_reply.started": "2022-01-15T04:57:17.81586Z"
    },
    "papermill": {
     "duration": 25.719783,
     "end_time": "2022-01-23T06:57:18.579245",
     "exception": false,
     "start_time": "2022-01-23T06:56:52.859462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 25.580305,
     "end_time": "2022-01-23T06:58:09.549193",
     "exception": false,
     "start_time": "2022-01-23T06:57:43.968888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T06:58:59.994590Z",
     "iopub.status.busy": "2022-01-23T06:58:59.994023Z",
     "iopub.status.idle": "2022-01-23T06:58:59.998606Z",
     "shell.execute_reply": "2022-01-23T06:58:59.998183Z",
     "shell.execute_reply.started": "2022-01-15T04:57:18.009945Z"
    },
    "papermill": {
     "duration": 24.922124,
     "end_time": "2022-01-23T06:58:59.998728",
     "exception": false,
     "start_time": "2022-01-23T06:58:35.076604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 584)\n"
     ]
    }
   ],
   "source": [
    "X_test = get_X(df_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T06:59:51.678805Z",
     "iopub.status.busy": "2022-01-23T06:59:51.677926Z",
     "iopub.status.idle": "2022-01-23T06:59:52.468053Z",
     "shell.execute_reply": "2022-01-23T06:59:52.468570Z",
     "shell.execute_reply.started": "2022-01-15T04:57:18.025123Z"
    },
    "papermill": {
     "duration": 26.521254,
     "end_time": "2022-01-23T06:59:52.468717",
     "exception": false,
     "start_time": "2022-01-23T06:59:25.947463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn: (3,)\n",
      "prediction will be made by: ['gbdt', 'mlp', 'cnn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_pred = pd.DataFrame()\n",
    "df_pred['row_id'] = df_test['stock_id'].astype(str) + '-' + df_test['time_id'].astype(str)\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "prediction_weights = {}\n",
    "\n",
    "if PREDICT_GBDT:\n",
    "    gbdt_preds = booster.predict(X_test)\n",
    "    predictions['gbdt'] = gbdt_preds\n",
    "    prediction_weights['gbdt'] = 4\n",
    "\n",
    "\n",
    "if PREDICT_MLP and mlp_model:\n",
    "    try:\n",
    "        mlp_preds = predict_nn(X_test, mlp_model, scaler, device, ensemble_method=ENSEMBLE_METHOD)\n",
    "        print(f'mlp: {mlp_preds.shape}')\n",
    "        predictions['mlp'] = mlp_preds\n",
    "        prediction_weights['mlp'] = 1\n",
    "    except:\n",
    "        print(f'failed to predict mlp: {traceback.format_exc()}')\n",
    "\n",
    "\n",
    "if PREDICT_CNN and cnn_model:\n",
    "    try:\n",
    "        cnn_preds = predict_nn(X_test, cnn_model, scaler, device, ensemble_method=ENSEMBLE_METHOD)\n",
    "        print(f'cnn: {cnn_preds.shape}')\n",
    "        predictions['cnn'] = cnn_preds\n",
    "        prediction_weights['cnn'] = 4\n",
    "    except:\n",
    "        print(f'failed to predict cnn: {traceback.format_exc()}')\n",
    "\n",
    "\n",
    "if PREDICT_TABNET and tab_model:\n",
    "    try:\n",
    "        tab_preds = predict_tabnet(X_test, tab_model, scaler, ensemble_method=ENSEMBLE_METHOD).flatten()\n",
    "        print(f'tab: {tab_preds.shape}')\n",
    "        predictions['tab'] = tab_preds\n",
    "        prediction_weights['tab'] = 1\n",
    "    except:\n",
    "        print(f'failed to predict tab: {traceback.format_exc()}')\n",
    "\n",
    "        \n",
    "overall_preds = None\n",
    "overall_weight = np.sum(list(prediction_weights.values()))\n",
    "\n",
    "print(f'prediction will be made by: {list(prediction_weights.keys())}')\n",
    "\n",
    "for name, preds in predictions.items():\n",
    "    w = prediction_weights[name] / overall_weight\n",
    "    if overall_preds is None:\n",
    "        overall_preds = preds * w\n",
    "    else:\n",
    "        overall_preds += preds * w\n",
    "        \n",
    "df_pred['target'] = np.clip(overall_preds, 0, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T07:00:43.579503Z",
     "iopub.status.busy": "2022-01-23T07:00:43.578812Z",
     "iopub.status.idle": "2022-01-23T07:00:43.602164Z",
     "shell.execute_reply": "2022-01-23T07:00:43.602580Z",
     "shell.execute_reply.started": "2022-01-15T04:57:18.056985Z"
    },
    "papermill": {
     "duration": 25.584209,
     "end_time": "2022-01-23T07:00:43.602727",
     "exception": false,
     "start_time": "2022-01-23T07:00:18.018518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(os.path.join(DATA_DIR, 'optiver-realized-volatility-prediction', 'sample_submission.csv'))\n",
    "submission = pd.merge(sub[['row_id']], df_pred[['row_id', 'target']], how='left')\n",
    "submission['target'] = submission['target'].fillna(0)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16517.385856,
   "end_time": "2022-01-23T07:01:10.301218",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-23T02:25:52.915362",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
